[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html",
    "title": "Hands-on Exercise 1: geospatial Data Wrangling with R",
    "section": "",
    "text": "In this section, i will install and load tidyverse and sf packages.\n\npacman::p_load(tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html#importing-a-geospatial-data-in-shapefile-format",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html#importing-a-geospatial-data-in-shapefile-format",
    "title": "Hands-on Exercise 1: geospatial Data Wrangling with R",
    "section": "Importing a geospatial data in shapefile format",
    "text": "Importing a geospatial data in shapefile format\n\nmpsz <- st_read(dsn = \"data/geospatial\", \n                layer= \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\HoYongQuan\\IS415-GAA(New)\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html#importing-polyline-feature-data-in-shapefile-form",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html#importing-polyline-feature-data-in-shapefile-form",
    "title": "Hands-on Exercise 1: geospatial Data Wrangling with R",
    "section": "Importing polyline feature data in shapefile form",
    "text": "Importing polyline feature data in shapefile form\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\HoYongQuan\\IS415-GAA(New)\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2248 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html#importing-gis-data-in-kml-format",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html#importing-gis-data-in-kml-format",
    "title": "Hands-on Exercise 1: geospatial Data Wrangling with R",
    "section": "Importing GIS data in kml format",
    "text": "Importing GIS data in kml format\n\npreschool = st_read(\"data/geospatial/preschools-location.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\HoYongQuan\\IS415-GAA(New)\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\preschools-location.kml' \n  using driver `KML'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html#working-with-st_geometry",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html#working-with-st_geometry",
    "title": "Hands-on Exercise 1: geospatial Data Wrangling with R",
    "section": "Working with st_geometry()",
    "text": "Working with st_geometry()\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html#working-with-glimpse",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html#working-with-glimpse",
    "title": "Hands-on Exercise 1: geospatial Data Wrangling with R",
    "section": "Working with glimpse",
    "text": "Working with glimpse\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO <int> 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  <chr> \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  <chr> \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     <chr> \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N <chr> \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C <chr> \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   <chr> \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   <chr> \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    <chr> \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D <date> 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     <dbl> 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     <dbl> 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng <dbl> 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area <dbl> 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   <MULTIPOLYGON [m]> MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html#working-with-head",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html#working-with-head",
    "title": "Hands-on Exercise 1: geospatial Data Wrangling with R",
    "section": "Working with head()",
    "text": "Working with head()\n\nhead(mpsz, n=5)  \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html#assigning-epsg-code-to-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html#assigning-epsg-code-to-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1: geospatial Data Wrangling with R",
    "section": "Assigning EPSG code to a simple feature data frame",
    "text": "Assigning EPSG code to a simple feature data frame\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nmpsz3414 <- st_set_crs(mpsz, 3414)\n\nWarning: st_crs<- : replacing crs does not reproject data; use st_transform for\nthat\n\n\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html#transforming-the-projection-of-preschool-from-wgs84-to-svy21",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html#transforming-the-projection-of-preschool-from-wgs84-to-svy21",
    "title": "Hands-on Exercise 1: geospatial Data Wrangling with R",
    "section": "Transforming the projection of preschool from wgs84 to svy21",
    "text": "Transforming the projection of preschool from wgs84 to svy21\n\npreschool3414 <- st_transform(preschool, \n                              crs = 3414)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html#importing-the-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html#importing-the-aspatial-data",
    "title": "Hands-on Exercise 1: geospatial Data Wrangling with R",
    "section": "Importing the aspatial data",
    "text": "Importing the aspatial data\n\nlistings <- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 6809 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (5): name, host_name, neighbourhood, room_type, license\ndbl  (11): id, host_id, latitude, longitude, price, minimum_nights, number_o...\nlgl   (1): neighbourhood_group\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nlist(listings) \n\n[[1]]\n# A tibble: 6,809 × 18\n       id name     host_id host_…¹ neigh…² neigh…³ latit…⁴ longi…⁵ room_…⁶ price\n    <dbl> <chr>      <dbl> <chr>   <lgl>   <chr>     <dbl>   <dbl> <chr>   <dbl>\n 1 816940 Old Sou… 4290554 Joyce   NA      Zuid       52.4    4.85 Entire…   165\n 2 528022 Somewhe… 2594559 Els     NA      Wester…    52.4    4.89 Privat…   100\n 3 538723 Beautif…  356740 Dimphy  NA      Waterg…    52.4    4.94 Entire…   140\n 4 549310 Family … 2699033 Barbara NA      De Baa…    52.4    4.86 Entire…   200\n 5 553514 B&B Wes…  618589 Mirjam  NA      Wester…    52.4    4.87 Entire…    80\n 6   2818 Quiet G…    3159 Daniel  NA      Oostel…    52.4    4.94 Privat…    59\n 7  20168 Studio …   59484 Alexan… NA      Centru…    52.4    4.89 Privat…   106\n 8  27886 Romanti…   97647 Flip    NA      Centru…    52.4    4.89 Privat…   140\n 9  28871 Comfort…  124245 Edwin   NA      Centru…    52.4    4.89 Privat…    75\n10  29051 Comfort…  124245 Edwin   NA      Centru…    52.4    4.89 Privat…    55\n# … with 6,799 more rows, 8 more variables: minimum_nights <dbl>,\n#   number_of_reviews <dbl>, last_review <date>, reviews_per_month <dbl>,\n#   calculated_host_listings_count <dbl>, availability_365 <dbl>,\n#   number_of_reviews_ltm <dbl>, license <chr>, and abbreviated variable names\n#   ¹​host_name, ²​neighbourhood_group, ³​neighbourhood, ⁴​latitude, ⁵​longitude,\n#   ⁶​room_type"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html#creating-a-simple-feature-data-frame-from-an-aspatial-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html#creating-a-simple-feature-data-frame-from-an-aspatial-data-frame",
    "title": "Hands-on Exercise 1: geospatial Data Wrangling with R",
    "section": "Creating a simple feature data frame from an aspatial data frame",
    "text": "Creating a simple feature data frame from an aspatial data frame\n\nlistings_sf <- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %>%\n  st_transform(crs = 3414)\n\n\nglimpse(listings_sf)\n\nRows: 6,809\nColumns: 17\n$ id                             <dbl> 816940, 528022, 538723, 549310, 553514,…\n$ name                           <chr> \"Old South Lovely Garden Apartment\", \"S…\n$ host_id                        <dbl> 4290554, 2594559, 356740, 2699033, 6185…\n$ host_name                      <chr> \"Joyce\", \"Els\", \"Dimphy\", \"Barbara\", \"M…\n$ neighbourhood_group            <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ neighbourhood                  <chr> \"Zuid\", \"Westerpark\", \"Watergraafsmeer\"…\n$ room_type                      <chr> \"Entire home/apt\", \"Private room\", \"Ent…\n$ price                          <dbl> 165, 100, 140, 200, 80, 59, 106, 140, 7…\n$ minimum_nights                 <dbl> 6, 2, 5, 2, 2, 3, 1, 2, 2, 2, 3, 3, 2, …\n$ number_of_reviews              <dbl> 63, 248, 57, 54, 162, 314, 339, 243, 45…\n$ last_review                    <date> 2022-11-28, 2022-11-28, 2020-01-01, 20…\n$ reviews_per_month              <dbl> 0.54, 3.30, 0.45, 0.60, 1.34, 1.88, 2.1…\n$ calculated_host_listings_count <dbl> 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 1, 1, …\n$ availability_365               <dbl> 11, 212, 0, 7, 1, 27, 0, 40, 91, 142, 0…\n$ number_of_reviews_ltm          <dbl> 2, 37, 0, 7, 0, 29, 0, 17, 84, 82, 7, 3…\n$ license                        <chr> \"03632A9BE56A736890D1\", \"0363 9289 A94D…\n$ geometry                       <POINT [m]> POINT (-4434165 10654894), POINT …"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html#buffering",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html#buffering",
    "title": "Hands-on Exercise 1: geospatial Data Wrangling with R",
    "section": "Buffering",
    "text": "Buffering\n\nbuffer_cycling <- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\n\nbuffer_cycling$AREA <- st_area(buffer_cycling)\n\n\nsum(buffer_cycling$AREA)\n\n1556978 [m^2]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html#point-in-polygon-count",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands-on_ex01.html#point-in-polygon-count",
    "title": "Hands-on Exercise 1: geospatial Data Wrangling with R",
    "section": "Point-in-polygon count",
    "text": "Point-in-polygon count\n\nmpsz3414$`PreSch Count`<- lengths(st_intersects(mpsz3414, preschool3414))\n\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    3.00    5.96    9.00   58.00 \n\n\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           58\n\n\n\nmpsz3414$Area <- mpsz3414 %>%\n  st_area()\n\n\nmpsz3414 <- mpsz3414 %>%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/hands-on_ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/hands-on_ex02.html",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, you will learn how to plot functional and truthful choropleth maps by using an R package called **tmap** package.\n\n\nIt is advisable for you to read the functional description of each function before using them."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/hands-on_ex02.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/hands-on_ex02.html#the-data",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "2.3.1 The Data",
    "text": "2.3.1 The Data\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/hands-on_ex02.html#importing-geospatial-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex02/hands-on_ex02.html#importing-geospatial-data-into-r",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "2.3.2 Importing Geospatial Data into R",
    "text": "2.3.2 Importing Geospatial Data into R\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz <- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\HoYongQuan\\IS415-GAA(New)\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nYou can examine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/hands-on_ex02.html#importing-attribute-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex02/hands-on_ex02.html#importing-attribute-data-into-r",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "2.3.3 Importing Attribute Data into R",
    "text": "2.3.3 Importing Attribute Data into R\nNext, we will import respopagsex2000to2018.csv file into RStudio and save the file into an R dataframe called popagsex.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata <- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/hands-on_ex02.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex02/hands-on_ex02.html#data-preparation",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "2.3.4 Data Preparation",
    "text": "2.3.4 Data Preparation\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n2.3.4.1 Data Wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 <- popdata %>%\n  filter(Time == 2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(`POP` = sum(`Pop`)) %>%\n  ungroup()%>%\n  pivot_wider(names_from=AG, \n              values_from=POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %>%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%>%\nmutate(`AGED`=rowSums(.[16:21])) %>%\nmutate(`TOTAL`=rowSums(.[3:21])) %>%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %>%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n2.3.4.2 Joining the attribute data and geospatial data\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 <- popdata2020 %>%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %>%\n  filter(`ECONOMY ACTIVE` > 0)\n\nWarning: `funs()` was deprecated in dplyr 0.8.0.\nℹ Please use a list of either functions or lambdas:\n\n# Simple named list: list(mean = mean, median = median)\n\n# Auto named with `tibble::lst()`: tibble::lst(mean, median)\n\n# Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))\n\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 <- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nThing to learn from the code chunk above:\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/hands-on_ex02.html#plotting-choropleth-map-quickly-by-using-qtm",
    "href": "Hands-on_Ex/Hands-on_Ex02/hands-on_ex02.html#plotting-choropleth-map-quickly-by-using-qtm",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "2.4.1 Plotting Choropleth map quickly by using qtm()",
    "text": "2.4.1 Plotting Choropleth map quickly by using qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/hands-on_ex02.html#creating-a-choropleth-map-by-using-tmaps-element",
    "href": "Hands-on_Ex/Hands-on_Ex02/hands-on_ex02.html#creating-a-choropleth-map-by-using-tmaps-element",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "2.4.2 Creating a choropleth map by using tmap’s element",
    "text": "2.4.2 Creating a choropleth map by using tmap’s element\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\n2.4.2.1 Drawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n2.4.2.2 Drawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\n2.4.2.3 Drawing a choropleth map using tm_fill() and tm_border()*\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/hands-on_ex02.html#data-classification-methods-of-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02/hands-on_ex02.html#data-classification-methods-of-tmap",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "2.4.3 Data classification methods of tmap",
    "text": "2.4.3 Data classification methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n2.4.3.1 Plotting choropleth maps with built-in classification methods\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n2.4.3.2 Plotting choropleth map with custome break\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6519  0.7025  0.7742  0.7645 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/hands-on_ex02.html#colour-scheme",
    "href": "Hands-on_Ex/Hands-on_Ex02/hands-on_ex02.html#colour-scheme",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "2.4.4 Colour Scheme",
    "text": "2.4.4 Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n2.4.4.1 Using ColourBrewer palette\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/hands-on_ex02.html#map-layouts",
    "href": "Hands-on_Ex/Hands-on_Ex02/hands-on_ex02.html#map-layouts",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "2.4.5 Map Layouts",
    "text": "2.4.5 Map Layouts\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n2.4.5.1 Map Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n2.4.5.2 Map style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n2.4.5.3 Cartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\""
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/hands-on_ex02.html#drawing-small-multiple-choropleth-maps",
    "href": "Hands-on_Ex/Hands-on_Ex02/hands-on_ex02.html#drawing-small-multiple-choropleth-maps",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "2.4.6 Drawing Small Multiple Choropleth Maps",
    "text": "2.4.6 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n2.4.6.1 By Assigning multiple values to at least one of the aesthetic arguments\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n2.4.6.2 By defining a group-by variable in tm_facets()\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n2.4.6.3 By creating multiple stand-alone maps with tmap_arrange()\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/hands-on_ex02.html#mapping-spatial-object-meeting-a-selection-criterion",
    "href": "Hands-on_Ex/Hands-on_Ex02/hands-on_ex02.html#mapping-spatial-object-meeting-a-selection-criterion",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "2.4.7 Mapping Spatial Object Meeting a Selection Criterion",
    "text": "2.4.7 Mapping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use selection function to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html",
    "title": "1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis is the evaluation of the pattern or distribution, of a set of points on a surface. The point can be location of:\n\nevents such as crime, traffic accident and disease onset, or\nbusiness services (coffee and fastfood outlets) or facilities such as childcare and eldercare.\n\nUsing appropriate functions of spatstat, this hands-on exercise aims to discover the spatial point processes of childecare centres in Singapore.\nThe specific questions we would like to answer are as follows:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#importing-the-spatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#importing-the-spatial-data",
    "title": "1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.4.1 Importing the spatial data",
    "text": "4.4.1 Importing the spatial data\nIn this section, st_read() of sf package will be used to import these three geospatial data sets into R.\n\nchildcare_sf <- st_read(\"data/child-care-services-geojson.geojson\") %>%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\HoYongQuan\\IS415-GAA(New)\\Hands-on_Ex\\Hands-on_Ex03\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf <- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\HoYongQuan\\IS415-GAA(New)\\Hands-on_Ex\\Hands-on_Ex03\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf <- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\HoYongQuan\\IS415-GAA(New)\\Hands-on_Ex\\Hands-on_Ex03\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nBefore we can use these data for analysis, it is important for us to ensure that they are projected in same projection system.\n\nsg_sf\n\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\nFirst 10 features:\n   GDO_GID MSLINK MAPID              COSTAL_NAM                       geometry\n1        1      1     0                 Linkway POLYGON ((14362.86 32307.49...\n2        2      3     0                 SENTOSA POLYGON ((25683.97 26236.91...\n3        3      5     0          PULAU SARIMBUN POLYGON ((11471.97 46273.01...\n4        4      6     0           PULAU SAMULUN POLYGON ((12602.3 32061.35,...\n5        5      7     0 SINGAPORE - MAIN ISLAND POLYGON ((17915.53 46770.73...\n6        6      8     0            PULAU KEPPEL POLYGON ((25606.84 27481.21...\n7        7      9     0             PULAU BRANI POLYGON ((27778.17 27321.28...\n8        8     10     0                   ISLET POLYGON ((25874.11 26121.48...\n9        9     11     0           PULAU PALAWAN POLYGON ((25937.33 25797.66...\n10      10     12     0                   ISLET POLYGON ((27459.33 24854.08...\n\n\n\nmpsz_sf\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#mapping-the-geospatial-data-sets",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#mapping-the-geospatial-data-sets",
    "title": "1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.4.2 Mapping the geospatial data sets",
    "text": "4.4.2 Mapping the geospatial data sets\nAfter checking the referencing system of each geospatial data data frame, it is also useful for us to plot a map to show their spatial patterns.\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nsf_use_s2(FALSE)\n\nSpherical geometry (s2) switched off\n\n\n\ntm_shape(sg_sf) +\n  tm_polygons() +\ntm_shape(mpsz_sf) +\n  tm_polygons() +\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\nNotice that all the geospatial layers are within the same map extend. This shows that their referencing system and coordinate values are referred to similar spatial context. This is very important in any geospatial analysis.\nAlternatively, we can also prepare a pin map by using the code chunk below.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\nNotice that at the interactive mode, tmap is using leaflet for R API. The advantage of this interactive pin map is it allows us to navigate and zoom around the map freely. We can also query the information of each simple feature (i.e. the point) by clicking of them. Last but not least, you can also change the background of the internet map layer. Currently, three internet map layers are provided. They are: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#converting-sf-data-frames-to-sps-spatial-class",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#converting-sf-data-frames-to-sps-spatial-class",
    "title": "1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.5.1 Converting sf data frames to sp’s Spatial* class",
    "text": "4.5.1 Converting sf data frames to sp’s Spatial* class\nThe code chunk below uses as_Spatial() of sf package to convert the three geospatial data from simple feature data frame to sp’s Spatial* class.\n\nchildcare <- as_Spatial(childcare_sf)\nmpsz <- as_Spatial(mpsz_sf)\nsg <- as_Spatial(sg_sf)\n\nDisplay information of the three Spatial* Classes as shown below\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>018989</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>08F73931F4A691F4</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \nmax values  : kml_999,                  <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>829646</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>RAFFLES KIDZ @ PUNGGOL PTE LTD</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>379D017BF244B0FA</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\nNotice that the geospatial data have been converted into their respective sp’s Spatial* classes now."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#converting-the-spatial-class-into-generic-sp-format",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#converting-the-spatial-class-into-generic-sp-format",
    "title": "1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.5.2 Converting the Spatial* class into generic sp format",
    "text": "4.5.2 Converting the Spatial* class into generic sp format\nspatstat requires the analytical data in ppp object form. There is no direct way to convert a Spatial* classes into ppp object. We need to convert the Spatial classes* into Spatial object first.\nThe codes chunk below converts the Spatial* classes into generic sp objects.\n\nchildcare_sp <- as(childcare, \"SpatialPoints\")\nsg_sp <- as(sg, \"SpatialPolygons\")\n\nNext, you should display the sp objects properties as shown below.\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "title": "1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.5.3 Converting the generic sp format into spatstat’s ppp format",
    "text": "4.5.3 Converting the generic sp format into spatstat’s ppp format\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp <- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nPlanar point pattern: 1545 points\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nNow, let us plot childcare_ppp and examine the different.\n\nplot(childcare_ppp)\n\n\n\n\nYou can take a quick look at the summary statistics of the newly created ppp object by using the code chunk below.\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nNotice the warning message about duplicates. In spatial point patterns analysis an issue of significant is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#handling-duplicated-points",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#handling-duplicated-points",
    "title": "1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.5.4 Handling duplicated points",
    "text": "4.5.4 Handling duplicated points\nWe can check the duplication in a ppp object by using the code chunk below\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nTo count the number of co-indicence point, we will use the multiplicity() function as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n   1    1    1    3    1    1    1    1    2    1    1    1    1    1    1    1 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n   1    1    1    1    1    1    1    1    1    1    9    1    1    1    1    1 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n   1    1    1    1    1    1    2    1    1    3    1    1    1    1    1    1 \n  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n   1    1    1    1    1    2    1    1    1    1    1    2    1    1    1    1 \n  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n   1    1    1    3    1    1    1    1    1    1    1    1    1    1    1    1 \n  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n   1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1 \n 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n   1    1    1    1    1    1    2    1    1    1    3    1    1    1    2    1 \n 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    3    2 \n 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n   1    2    1    1    1    2    2    3    1    5    1    5    1    1    1    2 \n 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n   1    1    1    1    2    1    1    1    1    1    1    2    1    1    1    1 \n 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n   1    4    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n   1    1    1    1    1    2    2    1    1    1    1    2    1    4    1    1 \n 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    1    1    1 \n 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    3 \n 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n   1    1    1    1    1    1    3    1    1    1    1    1    1    1    1    1 \n 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n   1    1    1    1    1    1    1    9    1    1    2    1    1    1    1    1 \n 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n   1    1    1    5    1    1    1    1    1    2    1    1    2    2    1    1 \n 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    2    2    1 \n 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n   1    1    1    1    9    1    1    1    1    1    1    1    1    1    1    1 \n 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n   1    1    2    1    1    1    1    1    1    1    2    1    1    1    1    1 \n 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n   1    1    1    1    1    1    1    2    1    1    2    1    1    1    1    1 \n 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n   1    1    9    9    1    1    1    1    1    1    1    1    1    1    2    1 \n 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    2    1    1 \n 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    2 \n 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n   1    1    1    1    1    1    1    1    1    1    1    2    1    1    3    1 \n 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n   1    1    1    1    1    1    1    1    1    3    1    1    1    1    1    1 \n 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n   2    2    2    1    1    1    1    2    1    1    2    1    1    1    2    1 \n 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n   1    2    1    1    1    1    1    9    1    4    1    2    1    1    1    1 \n 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n   2    1    1    1    1    1    1    1    2    1    2    1    1    1    1    1 \n 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n   1    1    1    1    1    1    1    1    1    2    1    2    1    1    1    1 \n 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    4 \n 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n   1    1    1    1    1    1    1    3    1    1    1    1    1    1    1    1 \n 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n   1    1    1    1    1    4    1    1    1    1    1    4    1    1    1    1 \n 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n   1    1    2    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n   1    1    1    1    1    1    1    1    1    4    1    1    1    1    1    1 \n 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n   1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1 \n 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n   3    1    1    1    2    1    1    1    3    1    1    3    1    1    1    1 \n 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 993  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 \n   1    1    1    1    1    1    1    1    1    2    2    1    1    1    1    1 \n1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 \n   1    1    1    1    1    1    1    1    2    2    1    1    1    5    1    1 \n1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 \n   1    9    1    2    2    1    1    1    2    1    1    1    1    1    1    1 \n1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 \n   1    1    1    1    2    1    1    1    3    1    1    1    1    1    1    1 \n1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 \n   9    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 \n   1    1    1    2    1    2    1    1    1    2    2    2    1    1    1    1 \n1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 \n   1    1    2    1    1    1    1    1    1    1    1    1    2    1    1    1 \n1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 \n   1    1    1    1    3    1    1    1    1    1    1    1    1    1    1    1 \n1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 \n   1    1    1    1    1    1    1    1    4    1    1    1    1    1    2    1 \n1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 \n   1    1    1    1    1    1    1    1    1    9    1    1    1    1    1    1 \n1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    2    1 \n1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    1 \n1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 \n   1    1    1    1    1    1    1    1    1    1    5    1    1    1    1    1 \n1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 \n   1    1    1    1    1    2    1    1    1    1    2    1    1    1    1    3 \n1537 1538 1539 1540 1541 1542 1543 1544 1545 \n   1    1    1    1    1    1    2    1    1 \n\n\nIf we want to know how many locations have more than one point event, we can use the code chunk below.\n\nsum(multiplicity(childcare_ppp) > 1)\n\n[1] 128\n\n\nThe output shows that there are 128 duplicated point events.\nTo view the locations of these duplicate point events, we will plot childcare data by using the code chunk below.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\nThere are three ways to overcome this problem. The easiest way is to delete the duplicates. But, that will also mean that some useful point events will be lost.\nThe second solution is use jittering, which will add a small perturbation to the duplicate points so that they do not occupy the exact same space.\nThe third solution is to make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\nThe code chunk below implements the jittering approach.\n\nchildcare_ppp_jit <- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#creating-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#creating-owin-object",
    "title": "1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.5.5 Creating owin object",
    "text": "4.5.5 Creating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin <- as(sg_sp, \"owin\")\n\nThe ouput object can be displayed by using plot() function\n\nplot(sg_owin)\n\n\n\n\nand summary() function of Base R.\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#combining-point-events-object-and-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#combining-point-events-object-and-owin-object",
    "title": "1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.5.6 Combining point events object and owin object",
    "text": "4.5.6 Combining point events object and owin object\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below.\n\nsummary(childcareSG_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 2.063463e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414\n\n\nplot the newly derived childcareSG_ppp as shown below.\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#kernel-density-estimation",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#kernel-density-estimation",
    "title": "1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.6.1 Kernel Density Estimation",
    "text": "4.6.1 Kernel Density Estimation\nIn this section, you will learn how to compute the kernel density estimation (KDE) of childcare services in Singapore.\n\n4.6.1.1 Computing kernel density estimation using automatic bandwidth selection method\nThe code chunk below computes a kernel density by using the following configurations of density() of spatstat:\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\nkde_childcareSG_bw <- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\n\nThe plot() function of Base R is then used to display the kernel density derived.\n\nplot(kde_childcareSG_bw)\n\n\n\n\nThe density values of the output range from 0 to 0.000035 which is way too small to comprehend. This is because the default unit of measurement of svy21 is in meter. As a result, the density values computed is in “number of points per square meter”.\nBefore we move on to next section, it is good to know that you can retrieve the bandwidth used to compute the kde layer by using the code chunk below.\n\nbw <- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n\n4.6.1.2 Rescalling KDE values\nIn the code chunk below, rescale() is used to covert the unit of measurement from meter to kilometer.\n\nchildcareSG_ppp.km <- rescale(childcareSG_ppp, 1000, \"km\")\n\nNow, we can re-run density() using the resale data set and plot the output kde map.\n\nkde_childcareSG.bw <- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nplot(kde_childcareSG.bw)\n\n\n\n\nNotice that output image looks identical to the earlier version, the only changes in the data values (refer to the legend)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#working-with-different-automatic-bandwidth-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#working-with-different-automatic-bandwidth-methods",
    "title": "1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.6.2 Working with different automatic bandwidth methods",
    "text": "4.6.2 Working with different automatic bandwidth methods\nBeside bw.diggle(), there are three other spatstat functions can be used to determine the bandwidth, they are: bw.CvL(), bw.scott(), and bw.ppl().\nLet us take a look at the bandwidth return by these automatic bandwidth calculation methods by using the code chunk below.\n\nbw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because in ther experience it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters. But they also insist that if the purpose of once study is to detect a single tight cluster in the midst of random noise then the bw.diggle() method seems to work best.\nThe code chunk beow will be used to compare the output of using bw.diggle and bw.ppl methods.\n\nkde_childcareSG.ppl <- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#working-with-different-kernel-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#working-with-different-kernel-methods",
    "title": "1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.6.3 Working with different kernel methods",
    "text": "4.6.3 Working with different kernel methods\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics.\nThe code chunk below will be used to compute three more kernel density estimations by using these three kernel function.\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#computing-kde-by-using-fixed-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#computing-kde-by-using-fixed-bandwidth",
    "title": "1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.7.1 Computing KDE by using fixed bandwidth",
    "text": "4.7.1 Computing KDE by using fixed bandwidth\nNext, you will compute a KDE layer by defining a bandwidth of 600 meter. Notice that in the code chunk below, the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp.km object is in kilometer, hence the 600m is 0.6km.\n\nkde_childcareSG_600 <- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nplot(kde_childcareSG_600)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#computing-kde-by-using-adaptive-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#computing-kde-by-using-adaptive-bandwidth",
    "title": "1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.7.2 Computing KDE by using adaptive bandwidth",
    "text": "4.7.2 Computing KDE by using adaptive bandwidth\nFixed bandwidth method is very sensitive to highly skew distribution of spatial point patterns over geographical units for example urban versus rural. One way to overcome this problem is by using adaptive bandwidth instead.\nIn this section, you will learn how to derive adaptive kernel density estimation by using density.adaptive() of spatstat.\n\nkde_childcareSG_adaptive <- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nplot(kde_childcareSG_adaptive)\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#converting-kde-output-into-grid-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#converting-kde-output-into-grid-object",
    "title": "1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.7.3 Converting KDE output into grid object",
    "text": "4.7.3 Converting KDE output into grid object\nThe result is the same, we just convert it so that it is suitable for mapping purposes\n\ngridded_kde_childcareSG_bw <- as.SpatialGridDataFrame.im(kde_childcareSG.bw)\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n4.7.3.1 Converting gridded output into raster\nNext, we will convert the gridded kernal density objects into RasterLayer object by using raster() of raster package.\n\nkde_childcareSG_bw_raster <- raster(gridded_kde_childcareSG_bw)\n\nLet us take a look at the properties of kde_childcareSG_bw_raster RasterLayer.\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\nNotice that the crs property is NA.\n\n\n4.7.3.2 Assigning projection systems\nThe code chunk below will be used to include the CRS information on kde_childcareSG_bw_raster RasterLayer.\n\nprojection(kde_childcareSG_bw_raster) <- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +init=EPSG:3414 \nsource     : memory\nnames      : v \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\nNotice that the crs property is completed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#visualing-the-output-in-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#visualing-the-output-in-tmap",
    "title": "1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.7.4 Visualing the output in tmap",
    "text": "4.7.4 Visualing the output in tmap\nFinally, we will display the raster in cartographic quality map using tmap package.\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\nVariable(s) \"v\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nNotice that the raster values are encoded explicitly onto the raster pixel using the values in “v”” field."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#comparing-spatial-point-patterns-using-kde",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#comparing-spatial-point-patterns-using-kde",
    "title": "1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.7.5 Comparing Spatial Point Patterns using KDE",
    "text": "4.7.5 Comparing Spatial Point Patterns using KDE\nIn this section, you will learn how to compare KDE of childcare at Ponggol, Tampines, Chua Chu Kang and Jurong West planning areas.\n\n4.7.5.1 Extracting Study Area\nThe code chunk below will be used to extract the target planning areas.\n\npg = mpsz[mpsz@data$PLN_AREA_N == \"PUNGGOL\",]\ntm = mpsz[mpsz@data$PLN_AREA_N == \"TAMPINES\",]\nck = mpsz[mpsz@data$PLN_AREA_N == \"CHOA CHU KANG\",]\njw = mpsz[mpsz@data$PLN_AREA_N == \"JURONG WEST\",]\n\nPlotting target planning areas\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\nplot(tm, main = \"Tampines\")\nplot(ck, main = \"Choa Chu Kang\")\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\n4.7.5.2 Converting the spatial data point frame into generic sp format\nNext, we will convert these SpatialPolygonsDataFrame layers into generic spatialpolygons layers.\n\npg_sp = as(pg, \"SpatialPolygons\")\ntm_sp = as(tm, \"SpatialPolygons\")\nck_sp = as(ck, \"SpatialPolygons\")\njw_sp = as(jw, \"SpatialPolygons\")\n\n\n\n4.7.5.3 Creating owin object\nNow, we will convert these SpatialPolygons objects into owin objects that is required by spatstat.\n\npg_owin = as(pg_sp, \"owin\")\ntm_owin = as(tm_sp, \"owin\")\nck_owin = as(ck_sp, \"owin\")\njw_owin = as(jw_sp, \"owin\")\n\n\n\n4.7.5.4 Combining childcare points and the study area\nBy using the code chunk below, we are able to extract childcare that is within the specific region to do our analysis later on.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres.\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\n4.7.5.5 Computing KDE\nThe code chunk below will be used to compute the KDE of these four planning area. bw.diggle method is used to derive the bandwidth of each\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\n\n\n\n\n\n\n4.7.5.6 Computing fixed bandwidth KDE\nFor comparison purposes, we will use 250m as the bandwidth.\n\npar(mfrow=c(2,2))\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#testing-spatial-point-patterns-using-clark-and-evans-test",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#testing-spatial-point-patterns-using-clark-and-evans-test",
    "title": "1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.8.1 Testing spatial point patterns using Clark and Evans Test",
    "text": "4.8.1 Testing spatial point patterns using Clark and Evans Test\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 28 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 10 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 9 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 29 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 29 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 28 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 28 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 29 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 8 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 31 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 30 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 34 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 11 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 28 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 9 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 32 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 7 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 30 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 11 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 32 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 32 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 99 simulations of CSR with fixed n\n\ndata:  childcareSG_ppp\nR = 0.54756, p-value = 0.01\nalternative hypothesis: clustered (R < 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#clark-and-evans-test-choa-chu-kang-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#clark-and-evans-test-choa-chu-kang-planning-area",
    "title": "1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.8.2 Clark and Evans Test: Choa Chu Kang planning area",
    "text": "4.8.2 Clark and Evans Test: Choa Chu Kang planning area\nIn the code chunk below, clarkevans.test() of spatstat is used to performs Clark-Evans test of aggregation for childcare centre in Choa Chu Kang planning area.\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 999 simulations of CSR with fixed n\n\ndata:  childcare_ck_ppp\nR = 0.90642, p-value = 0.036\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#clark-and-evans-test-tampines-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands-on_ex03.html#clark-and-evans-test-tampines-planning-area",
    "title": "1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.8.3 Clark and Evans Test: Tampines planning area",
    "text": "4.8.3 Clark and Evans Test: Tampines planning area\nIn the code chunk below, the similar test is used to analyse the spatial point patterns of childcare centre in Tampines planning area.\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 999 simulations of CSR with fixed n\n\ndata:  childcare_tm_ppp\nR = 0.7965, p-value = 0.002\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html",
    "title": "5 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis is the evaluation of the pattern or distribution, of a set of points on a surface. The point can be location of:\n\nevents such as crime, traffic accident and disease onset, or\nbusiness services (coffee and fastfood outlets) or facilities such as childcare and eldercare.\n\nUsing appropriate functions of spatstat, this hands-on exercise aims to discover the spatial point processes of childecare centres in Singapore.\nThe specific questions we would like to answer are as follows:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#importing-the-spatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#importing-the-spatial-data",
    "title": "5 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.4.1 Importing the Spatial data",
    "text": "5.4.1 Importing the Spatial data\nIn this section, st_read() of sf package will be used to import these three geospatial data sets into R.\n\nchildcare_sf <- st_read(\"data/child-care-services-geojson.geojson\") %>%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\HoYongQuan\\IS415-GAA(New)\\Hands-on_Ex\\Hands-on_Ex03.1\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf <- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\HoYongQuan\\IS415-GAA(New)\\Hands-on_Ex\\Hands-on_Ex03.1\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf <- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\HoYongQuan\\IS415-GAA(New)\\Hands-on_Ex\\Hands-on_Ex03.1\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nAssigning Correct CRS Values\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#mapping-the-geospatial-data-sets",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#mapping-the-geospatial-data-sets",
    "title": "5 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.4.2 Mapping the geospatial data sets",
    "text": "5.4.2 Mapping the geospatial data sets\n\ntm_shape(sg_sf) +\n  tm_polygons() +\ntm_shape(mpsz_sf) +\n  tm_polygons() +\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\nNotice that all the geospatial layers are within the same map extend. This shows that their referencing system and coordinate values are referred to similar spatial context. This is very important in any geospatial analysis.\nAlternatively, we can also prepare a pin map by using the code chunk below.\n\ntmap_mode('view')\n\n\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\n\n\ntmap_mode('plot')\n\nNotice that at the interactive mode, tmap is using leaflet for R API. The advantage of this interactive pin map is it allows us to navigate and zoom around the map freely. We can also query the information of each simple feature (i.e. the point) by clicking of them. Last but not least, you can also change the background of the internet map layer. Currently, three internet map layers are provided. They are: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas.\n\n\n\n\n\n\nRemember to switch back to plot mode after the interactive map. This is because, each interactive mode will consume a connection. You should also avoid displaying ecessive numbers of interactive maps (i.e. not more than 10) in one RMarkdown document when publish on Netlify."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#converting-sf-data-frames-to-sps-spatial-class",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#converting-sf-data-frames-to-sps-spatial-class",
    "title": "5 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.5.1 Converting sf data frames to sp’s Spatial* class",
    "text": "5.5.1 Converting sf data frames to sp’s Spatial* class\nThe code chunk below uses as_Spatial() of sf package to convert the three geospatial data from simple feature data frame to sp’s Spatial* class.\n\nchildcare <- as_Spatial(childcare_sf)\nmpsz <- as_Spatial(mpsz_sf)\nsg <- as_Spatial(sg_sf)\n\ndisplay the information of the three spatial* classes as shown below.\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>018989</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>08F73931F4A691F4</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \nmax values  : kml_999,                  <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>829646</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>RAFFLES KIDZ @ PUNGGOL PTE LTD</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>379D017BF244B0FA</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\nNotice that the geospatial data have been converted into their respective sp’s Spatial* classes now."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#converting-the-spatial-class-into-generic-sp-format",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#converting-the-spatial-class-into-generic-sp-format",
    "title": "5 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.5.2 Converting the Spatial* class into generic sp format",
    "text": "5.5.2 Converting the Spatial* class into generic sp format\nspatstat requires the analytical data in ppp object form. There is no direct way to convert a Spatial* classes into ppp object. We need to convert the Spatial classes* into Spatial object first.\nThe codes chunk below converts the Spatial* classes into generic sp objects.\n\nchildcare_sp <- as(childcare, \"SpatialPoints\")\nsg_sp <- as(sg, \"SpatialPolygons\")\n\nNext, you should display the sp objects properties\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "title": "5 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.5.3 Converting the generic sp format into spatstat’s ppp format",
    "text": "5.5.3 Converting the generic sp format into spatstat’s ppp format\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp <- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nPlanar point pattern: 1545 points\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nNow, let us plot childcare_ppp and examine the different.\n\nplot(childcare_ppp)\n\n\n\n\nYou can take a quick look at the summary statistics of the newly created ppp object by using the code chunk below.\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nNotice the warning message about duplicates. In spatial point patterns analysis an issue of significant is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#handling-duplicated-points",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#handling-duplicated-points",
    "title": "5 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.5.4 Handling duplicated points",
    "text": "5.5.4 Handling duplicated points\nWe can check the duplication in a ppp object by using the code chunk below.\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nTo count the number of co-indicence point, we will use the multiplicity() function as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n   1    1    1    3    1    1    1    1    2    1    1    1    1    1    1    1 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n   1    1    1    1    1    1    1    1    1    1    9    1    1    1    1    1 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n   1    1    1    1    1    1    2    1    1    3    1    1    1    1    1    1 \n  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n   1    1    1    1    1    2    1    1    1    1    1    2    1    1    1    1 \n  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n   1    1    1    3    1    1    1    1    1    1    1    1    1    1    1    1 \n  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n   1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1 \n 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n   1    1    1    1    1    1    2    1    1    1    3    1    1    1    2    1 \n 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    3    2 \n 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n   1    2    1    1    1    2    2    3    1    5    1    5    1    1    1    2 \n 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n   1    1    1    1    2    1    1    1    1    1    1    2    1    1    1    1 \n 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n   1    4    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n   1    1    1    1    1    2    2    1    1    1    1    2    1    4    1    1 \n 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    1    1    1 \n 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    3 \n 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n   1    1    1    1    1    1    3    1    1    1    1    1    1    1    1    1 \n 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n   1    1    1    1    1    1    1    9    1    1    2    1    1    1    1    1 \n 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n   1    1    1    5    1    1    1    1    1    2    1    1    2    2    1    1 \n 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    2    2    1 \n 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n   1    1    1    1    9    1    1    1    1    1    1    1    1    1    1    1 \n 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n   1    1    2    1    1    1    1    1    1    1    2    1    1    1    1    1 \n 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n   1    1    1    1    1    1    1    2    1    1    2    1    1    1    1    1 \n 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n   1    1    9    9    1    1    1    1    1    1    1    1    1    1    2    1 \n 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    2    1    1 \n 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    2 \n 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n   1    1    1    1    1    1    1    1    1    1    1    2    1    1    3    1 \n 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n   1    1    1    1    1    1    1    1    1    3    1    1    1    1    1    1 \n 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n   2    2    2    1    1    1    1    2    1    1    2    1    1    1    2    1 \n 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n   1    2    1    1    1    1    1    9    1    4    1    2    1    1    1    1 \n 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n   2    1    1    1    1    1    1    1    2    1    2    1    1    1    1    1 \n 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n   1    1    1    1    1    1    1    1    1    2    1    2    1    1    1    1 \n 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    4 \n 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n   1    1    1    1    1    1    1    3    1    1    1    1    1    1    1    1 \n 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n   1    1    1    1    1    4    1    1    1    1    1    4    1    1    1    1 \n 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n   1    1    2    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n   1    1    1    1    1    1    1    1    1    4    1    1    1    1    1    1 \n 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n   1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1 \n 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n   3    1    1    1    2    1    1    1    3    1    1    3    1    1    1    1 \n 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 993  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 \n   1    1    1    1    1    1    1    1    1    2    2    1    1    1    1    1 \n1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 \n   1    1    1    1    1    1    1    1    2    2    1    1    1    5    1    1 \n1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 \n   1    9    1    2    2    1    1    1    2    1    1    1    1    1    1    1 \n1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 \n   1    1    1    1    2    1    1    1    3    1    1    1    1    1    1    1 \n1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 \n   9    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 \n   1    1    1    2    1    2    1    1    1    2    2    2    1    1    1    1 \n1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 \n   1    1    2    1    1    1    1    1    1    1    1    1    2    1    1    1 \n1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 \n   1    1    1    1    3    1    1    1    1    1    1    1    1    1    1    1 \n1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 \n   1    1    1    1    1    1    1    1    4    1    1    1    1    1    2    1 \n1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 \n   1    1    1    1    1    1    1    1    1    9    1    1    1    1    1    1 \n1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    2    1 \n1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    1 \n1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 \n   1    1    1    1    1    1    1    1    1    1    5    1    1    1    1    1 \n1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 \n   1    1    1    1    1    2    1    1    1    1    2    1    1    1    1    3 \n1537 1538 1539 1540 1541 1542 1543 1544 1545 \n   1    1    1    1    1    1    2    1    1 \n\n\nIf we want to know how many locations have more than one point event, we can use the code chunk below.\n\nsum(multiplicity(childcare_ppp) > 1)\n\n[1] 128\n\n\nThe output shows that there are 128 duplicated point events.\nTo view the locations of these duplicate point events, we will plot childcare data by using the code chunk below.\n\ntmap_mode('view')\n\n\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\n\ntmap_mode('plot')\n\nThere are three ways to overcome this problem. The easiest way is to delete the duplicates. But, that will also mean that some useful point events will be lost.\nThe second solution is use jittering, which will add a small perturbation to the duplicate points so that they do not occupy the exact same space.\nThe third solution is to make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\nThe code chunk below implements the jittering approach.\n\nchildcare_ppp_jit <- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#creating-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#creating-owin-object",
    "title": "5 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.5.5 Creating owin object",
    "text": "5.5.5 Creating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin <- as(sg_sp, \"owin\")\n\nThe ouput object can be displayed by using plot() function\n\nplot(sg_owin)\n\n\n\n\nand summary() function of Base R.\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#combining-point-events-object-and-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#combining-point-events-object-and-owin-object",
    "title": "5 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.5.6 Combining point events object and owin object",
    "text": "5.5.6 Combining point events object and owin object\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below.\n\nsummary(childcareSG_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 2.063463e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414\n\n\nNewly plotted derived childcareSG_ppp\n\nplot(childcareSG_ppp)\n\n\n\n\n\n5.5.6.1 Extracting study area\nThe code chunk below will be used to extract the target planning areas\n\npg = mpsz[mpsz@data$PLN_AREA_N == \"PUNGGOL\",]\ntm = mpsz[mpsz@data$PLN_AREA_N == \"TAMPINES\",]\nck = mpsz[mpsz@data$PLN_AREA_N == \"CHOA CHU KANG\",]\njw = mpsz[mpsz@data$PLN_AREA_N == \"JURONG WEST\",]\n\nPlotting target planning areas\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\nplot(tm, main = \"Tampines\")\nplot(ck, main = \"Choa Chu Kang\")\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\n5.5.6.2 Converting the spatial point data frame into generic sp format\nNext, we will convert these SpatialPolygonsDataFrame layers into generic spatialpolygons layers.\n\npg_sp = as(pg, \"SpatialPolygons\")\ntm_sp = as(tm, \"SpatialPolygons\")\nck_sp = as(ck, \"SpatialPolygons\")\njw_sp = as(jw, \"SpatialPolygons\")\n\n\n\n5.5.6.3 Creating owin object\nNow, we will convert these SpatialPolygons objects into owin objects that is required by spatstat.\n\npg_owin = as(pg_sp, \"owin\")\ntm_owin = as(tm_sp, \"owin\")\nck_owin = as(ck_sp, \"owin\")\njw_owin = as(jw_sp, \"owin\")\n\n\n\n5.5.6.4 Combining childcare points and the study area\nBy using the code chunk below, we are able to extract childcare that is within the specific region to do our analysis later on.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres.\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#choa-chu-kang-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#choa-chu-kang-planning-area",
    "title": "5 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.7.1 Choa Chu Kang planning area",
    "text": "5.7.1 Choa Chu Kang planning area\n\n5.7.1.1 Computing G-function estimation\nThe code chunk below is used to compute G-function using Gest() of spatat package.\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n5.7.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-function\n\nG_CK.csr <- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60........\n.70.........80.........90.........100.........110.........120.........130......\n...140.........150.........160.........170.........180.........190.........200....\n.....210.........220.........230.........240.........250.........260.........270..\n.......280.........290.........300.........310.........320.........330.........340\n.........350.........360.........370.........380.........390.........400........\n.410.........420.........430.........440.........450.........460.........470......\n...480.........490.........500.........510.........520.........530.........540....\n.....550.........560.........570.........580.........590.........600.........610..\n.......620.........630.........640.........650.........660.........670.........680\n.........690.........700.........710.........720.........730.........740........\n.750.........760.........770.........780.........790.........800.........810......\n...820.........830.........840.........850.........860.........870.........880....\n.....890.........900.........910.........920.........930.........940.........950..\n.......960.........970.........980.........990........ 999.\n\nDone.\n\n\n\nplot(G_CK.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#tampines-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#tampines-planning-area",
    "title": "5 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.7.2 Tampines planning area",
    "text": "5.7.2 Tampines planning area\n\n5.7.2.1 Computing G-Function estimation\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n5.7.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nG_tm.csr <- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60........\n.70.........80.........90.........100.........110.........120.........130......\n...140.........150.........160.........170.........180.........190.........200....\n.....210.........220.........230.........240.........250.........260.........270..\n.......280.........290.........300.........310.........320.........330.........340\n.........350.........360.........370.........380.........390.........400........\n.410.........420.........430.........440.........450.........460.........470......\n...480.........490.........500.........510.........520.........530.........540....\n.....550.........560.........570.........580.........590.........600.........610..\n.......620.........630.........640.........650.........660.........670.........680\n.........690.........700.........710.........720.........730.........740........\n.750.........760.........770.........780.........790.........800.........810......\n...820.........830.........840.........850.........860.........870.........880....\n.....890.........900.........910.........920.........930.........940.........950..\n.......960.........970.........980.........990........ 999.\n\nDone.\n\n\n\nplot(G_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#choa-chu-kang-planning-area-1",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#choa-chu-kang-planning-area-1",
    "title": "5 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.8.1 Choa Chu Kang Planning Area",
    "text": "5.8.1 Choa Chu Kang Planning Area\n\n5.8.1.1 Computing F-function estimation\nThe code chunk below is used to compute F-function using Fest() of spatat package.\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#performing-complete-spatial-randomness-test-2",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#performing-complete-spatial-randomness-test-2",
    "title": "5 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.8.2 Performing Complete Spatial Randomness Test",
    "text": "5.8.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-function\n\nF_CK.csr <- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60........\n.70.........80.........90.........100.........110.........120.........130......\n...140.........150.........160.........170.........180.........190.........200....\n.....210.........220.........230.........240.........250.........260.........270..\n.......280.........290.........300.........310.........320.........330.........340\n.........350.........360.........370.........380.........390.........400........\n.410.........420.........430.........440.........450.........460.........470......\n...480.........490.........500.........510.........520.........530.........540....\n.....550.........560.........570.........580.........590.........600.........610..\n.......620.........630.........640.........650.........660.........670.........680\n.........690.........700.........710.........720.........730.........740........\n.750.........760.........770.........780.........790.........800.........810......\n...820.........830.........840.........850.........860.........870.........880....\n.....890.........900.........910.........920.........930.........940.........950..\n.......960.........970.........980.........990........ 999.\n\nDone.\n\n\n\nplot(F_CK.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#tampines-planning-area-1",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#tampines-planning-area-1",
    "title": "5 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.8.3 Tampines Planning Area",
    "text": "5.8.3 Tampines Planning Area\n\n5.8.3.1 Computing F-Function estimation\nMonte Carlo Test with F-Function\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n5.8.3.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nF_tm.csr <- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60........\n.70.........80.........90.........100.........110.........120.........130......\n...140.........150.........160.........170.........180.........190.........200....\n.....210.........220.........230.........240.........250.........260.........270..\n.......280.........290.........300.........310.........320.........330.........340\n.........350.........360.........370.........380.........390.........400........\n.410.........420.........430.........440.........450.........460.........470......\n...480.........490.........500.........510.........520.........530.........540....\n.....550.........560.........570.........580.........590.........600.........610..\n.......620.........630.........640.........650.........660.........670.........680\n.........690.........700.........710.........720.........730.........740........\n.750.........760.........770.........780.........790.........800.........810......\n...820.........830.........840.........850.........860.........870.........880....\n.....890.........900.........910.........920.........930.........940.........950..\n.......960.........970.........980.........990........ 999.\n\nDone.\n\n\n\nplot(F_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#choa-chu-kang-planning-area-2",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#choa-chu-kang-planning-area-2",
    "title": "5 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.9.1 Choa Chu Kang Planning Area",
    "text": "5.9.1 Choa Chu Kang Planning Area\n\n5.9.1.1 Computing K-Function Estimate\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n5.9.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_ck.csr <- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\n\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#tampines-planning-area-2",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#tampines-planning-area-2",
    "title": "5 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.9.2 Tampines planning area",
    "text": "5.9.2 Tampines planning area\n\n5.9.2.1 Computing K-Function estimation\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n5.9.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_tm.csr <- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#choa-chu-kang-planning-area-3",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#choa-chu-kang-planning-area-3",
    "title": "5 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.10.1 Choa Chu Kang Planning Area",
    "text": "5.10.1 Choa Chu Kang Planning Area\n\n5.10.1.1 Computing L Function estimation\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n5.10.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nL_ck.csr <- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#tampines-planning-area-3",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/hands-on_ex03.1.html#tampines-planning-area-3",
    "title": "5 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.10.2 Tampines Planning Area",
    "text": "5.10.2 Tampines Planning Area\n\n5.10.2.1 Computing L-Function estimate\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n5.10.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below will be used to perform the hypothesis testing.\n\nL_tm.csr <- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\n\nThen, plot the model output by using the code chunk below.\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex02/in-class_ex02.html",
    "href": "In-Class_Ex/In-Class_Ex02/in-class_ex02.html",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "",
    "text": "Water is an important resource to mankind. Clean and accessible water is critical to human health. It provides a healthy environment, a sustainable economy, reduces poverty and ensures peace and security. Yet over 40% of the global population does not have access to sufficient clean water. By 2025, 1.8 billion people will be living in countries or regions with absolute water scarcity, according to UN-Water. The lack of water poses a major threat to several sectors, including food security. Agriculture uses about 70% of the world’s accessible freshwater.\nDeveloping countries are most affected by water shortages and poor water quality. Up to 80% of illnesses in the developing world are linked to inadequate water and sanitation. Despite technological advancement, providing clean water to the rural community is still a major development issues in many countries globally, especially countries in the Africa continent.\nTo address the issue of providing clean and sustainable water supply to the rural community, a global Water Point Data Exchange (WPdx) project has been initiated. The main aim of this initiative is to collect water point related data from rural areas at the water point or small water scheme level and share the data via WPdx Data Repository, a cloud-based data library. What is so special of this project is that data are collected based on WPDx Data Standard.\n\n\n\nGeospatial analytics hold tremendous potential to address complex problems facing society. In this study, you are tasked to apply appropriate geospatial data wrangling methods to prepare the data for water point mapping study. For the purpose of this study, Nigeria will be used as the study country.\n\n\n\n\n\nFor the purpose of this assignment, data from WPdx Global Data Repositories will be used. There are two versions of the data. They are: WPdx-Basic and WPdx+. You are required to use WPdx+ data set.\n\n\n\nNigeria Level-2 Administrative Boundary (also known as Local Government Area) polygon features GIS data will be used in this take-home exercise. The data can be downloaded either from The Humanitarian Data Exchange portal or geoBoundaries.\n\n\n\n\nThe specific tasks of this take-home exercise are as follows:\n\nUsing appropriate sf method, import the shapefile into R and save it in a simple feature data frame format. Note that there are three Projected Coordinate Systems of Nigeria, they are: EPSG: 26391, 26392, and 26303. You can use any one of them.\nUsing appropriate tidyr and dplyr methods, derive the number of functional and non-functional water points at LGA level.\nCombining the geospatial and aspatial data frame into simple feature data frame.\nVisualising the distribution of water point by using appropriate statistical methods."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex02/in-class_ex02.html#importing-geospatial-data",
    "href": "In-Class_Ex/In-Class_Ex02/in-class_ex02.html#importing-geospatial-data",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "3.1 Importing Geospatial Data",
    "text": "3.1 Importing Geospatial Data\n\n3.1.1 The geoBoundaries data set\n#readings in metres\n\ngeoNGA <- st_read(\"data/geospatial/\",\n                  layer = \"geoBoundaries-NGA-ADM2\") %>% \n  st_transform(crs = 26392)\n\nReading layer `geoBoundaries-NGA-ADM2' from data source \n  `C:\\HoYongQuan\\IS415-GAA(New)\\In-Class_Ex\\In-Class_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\n\n\n3.1.2 The NGA dataset\n\nNGA <- st_read(\"data/geospatial/\",\n               layer = \"nga_admbnda_adm2_osgof_20190417\") %>%\n  st_transform(crs = 26392)\n\nReading layer `nga_admbnda_adm2_osgof_20190417' from data source \n  `C:\\HoYongQuan\\IS415-GAA(New)\\In-Class_Ex\\In-Class_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex02/in-class_ex02.html#importing-aspatial-data",
    "href": "In-Class_Ex/In-Class_Ex02/in-class_ex02.html#importing-aspatial-data",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "3.2 Importing Aspatial Data",
    "text": "3.2 Importing Aspatial Data\n\nwp_nga <- read_csv(\"data/aspatial/WPdx.csv\") %>%\n  filter(`#clean_country_name` == \"Nigeria\")\n\n\n3.2.1 Converting Aspatial Data into Geospatial\nConverting an aspatial data into an sf data.frame involves two steps.\nFirst, we need to convert the wkt field into sfc field by using st_as_sfc() data type.\n\nwp_nga$Geometry = st_as_sfc(wp_nga$`New Georeferenced Column`)\nwp_nga\n\n# A tibble: 95,008 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n    <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429068 GRID3             7.98    5.12 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2 222071 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n 3 160612 WaterAid          6.49    7.93 12/04/… Yes     Boreho… Well    Hand P…\n 4 160669 WaterAid          6.73    7.65 12/04/… Yes     Boreho… Well    <NA>   \n 5 160642 WaterAid          6.78    7.66 12/04/… Yes     Boreho… Well    Hand P…\n 6 160628 WaterAid          6.96    7.78 12/04/… Yes     Boreho… Well    Hand P…\n 7 160632 WaterAid          7.02    7.84 12/04/… Yes     Boreho… Well    Hand P…\n 8 642747 Living Water …    7.33    8.98 10/03/… Yes     Boreho… Well    Mechan…\n 9 642456 Living Water …    7.17    9.11 10/03/… Yes     Boreho… Well    Hand P…\n10 641347 Living Water …    7.20    9.22 03/28/… Yes     Boreho… Well    Hand P…\n# … with 94,998 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\nNext, we will convert the tibble data.frame into an sf object by using st_sf(). It is also important for us to include the referencing system of the data into the sf object.\n\nwp_sf <- st_sf(wp_nga, crs=4326)\nwp_sf\n\nSimple feature collection with 95008 features and 70 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 2.707441 ymin: 4.301812 xmax: 14.21828 ymax: 13.86568\nGeodetic CRS:  WGS 84\n# A tibble: 95,008 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n *  <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429068 GRID3             7.98    5.12 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2 222071 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n 3 160612 WaterAid          6.49    7.93 12/04/… Yes     Boreho… Well    Hand P…\n 4 160669 WaterAid          6.73    7.65 12/04/… Yes     Boreho… Well    <NA>   \n 5 160642 WaterAid          6.78    7.66 12/04/… Yes     Boreho… Well    Hand P…\n 6 160628 WaterAid          6.96    7.78 12/04/… Yes     Boreho… Well    Hand P…\n 7 160632 WaterAid          7.02    7.84 12/04/… Yes     Boreho… Well    Hand P…\n 8 642747 Living Water …    7.33    8.98 10/03/… Yes     Boreho… Well    Mechan…\n 9 642456 Living Water …    7.17    9.11 10/03/… Yes     Boreho… Well    Hand P…\n10 641347 Living Water …    7.20    9.22 03/28/… Yes     Boreho… Well    Hand P…\n# … with 94,998 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\n\n\n3.2.2. Transforming into Nigeria projected coordinate system\n\nwp_sf <- wp_sf %>%\n  st_transform(crs = 26392)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex02/in-class_ex02.html#excluding-redundant-fields",
    "href": "In-Class_Ex/In-Class_Ex02/in-class_ex02.html#excluding-redundant-fields",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "4.1 Excluding redundant fields",
    "text": "4.1 Excluding redundant fields\nNGA sf data.frame consists of many redundent fields. The code chunk below uses select() of dplyr to retain column 3, 4, 8 and 9. Do you know why?\n\nNGA <- NGA %>%\n  select(c(3:4, 8:9))"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex02/in-class_ex02.html#checking-for-duplicate-name",
    "href": "In-Class_Ex/In-Class_Ex02/in-class_ex02.html#checking-for-duplicate-name",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "4.2 Checking for duplicate name",
    "text": "4.2 Checking for duplicate name\nIt is always important to check for duplicate name in the data main data fields. Using duplicated() of Base R, we can flag out LGA names that might be duplicated as shown in the code chunk below.\n\nNGA$ADM2_EN[duplicated(NGA$ADM2_EN)==TRUE]\n\n[1] \"Bassa\"    \"Ifelodun\" \"Irepodun\" \"Nasarawa\" \"Obi\"      \"Surulere\"\n\n\nThe printout above shows that there are 6 LGAs with the same name. A Google search using the coordinates showed that there are LGAs with the same name but are located in different states. For instances, there is a Bassa LGA in Kogi State and a Bassa LGA in Plateau State.\nLet us correct these errors by using the code chunk below.\n\nNGA$ADM2_EN[94] <- \"Bassa, Kogi\"\nNGA$ADM2_EN[95] <- \"Bassa, Plateau\"\nNGA$ADM2_EN[304] <- \"Ifelodun, Kwara\"\nNGA$ADM2_EN[305] <- \"Ifelodun, Osun\"\nNGA$ADM2_EN[355] <- \"Irepodun, Kwara\"\nNGA$ADM2_EN[356] <- \"Irepodun, Osun\"\nNGA$ADM2_EN[519] <- \"Nasarawa, Kano\"\nNGA$ADM2_EN[520] <- \"Nasarawa, Nasarawa\"\nNGA$ADM2_EN[546] <- \"Obi, Benue\"\nNGA$ADM2_EN[547] <- \"Obi, Nasarawa\"\nNGA$ADM2_EN[693] <- \"Surulere, Lagos\"\nNGA$ADM2_EN[694] <- \"Surulere, Oyo\"\n\nNow, let us rerun the code chunk below to confirm that the duplicated name issue has been addressed.\n\nNGA$ADM2_EN[duplicated(NGA$ADM2_EN)==TRUE]\n\ncharacter(0)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex02/in-class_ex02.html#extracting-water-point-data",
    "href": "In-Class_Ex/In-Class_Ex02/in-class_ex02.html#extracting-water-point-data",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "5.1 Extracting Water Point Data",
    "text": "5.1 Extracting Water Point Data\nThe code chunk below is used to extract functional water point.\n\nwp_functional <- wp_sf_nga %>%\n  filter(status_clean %in%\n           c(\"Functional\",\n             \"Functional but not in use\",\n             \"Functional but needs repair\"))\n\nThe code chunk below is used to extract functional water point.\n\nwp_nonfunctional <- wp_sf_nga %>%\n  filter(status_clean %in%\n           c(\"Abandoned/Decommissioned\",\n             \"Abandoned\",\n             \"Non-Functional due to dry season\",\n             \"Non-Functional\",\n             \"Non functional due to dry season\"))\n\nThe code chunk below is used to extract water point with unknown status.\n\nwp_unknown <- wp_sf_nga %>%\n  filter(status_clean == \"unknown\")\n\nNext,the code chunk below is used to perform a quick EDA on the derived sf data.frames.\n\nfreq(data = wp_functional,\n     input = 'status_clean')\n\n\n\n\n                 status_clean frequency percentage cumulative_perc\n1                  Functional     45883      87.99           87.99\n2 Functional but needs repair      4579       8.78           96.77\n3   Functional but not in use      1686       3.23          100.00\n\n\n\nfreq(data = wp_nonfunctional,\n     input = 'status_clean')\n\n\n\n\n                      status_clean frequency percentage cumulative_perc\n1                   Non-Functional     29385      91.25           91.25\n2 Non-Functional due to dry season      2403       7.46           98.71\n3         Abandoned/Decommissioned       234       0.73           99.44\n4                        Abandoned       175       0.54           99.98\n5 Non functional due to dry season         7       0.02          100.00\n\n\n\nfreq(data = wp_unknown,\n     input = 'status_clean')\n\n\n\n\n  status_clean frequency percentage cumulative_perc\n1      unknown     10656        100             100"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex02/in-class_ex02.html#performing-point-in-polygon-count",
    "href": "In-Class_Ex/In-Class_Ex02/in-class_ex02.html#performing-point-in-polygon-count",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "5.2 Performing Point-in-Polygon Count",
    "text": "5.2 Performing Point-in-Polygon Count\nNext, we want to find out the number of total, functional, nonfunctional and unknown water points in each LGA. This is performed in the following code chunk. First, it identifies the functional water points in each LGA by using st_intersects() of sf package. Next, length() is used to calculate the number of functional water points that fall inside each LGA.\n\nNGA_wp <- NGA %>% \n  mutate(`total_wp` = lengths(\n    st_intersects(NGA, wp_sf_nga))) %>%\n  mutate(`wp_functional` = lengths(\n    st_intersects(NGA, wp_functional))) %>%\n  mutate(`wp_nonfunctional` = lengths(\n    st_intersects(NGA, wp_nonfunctional))) %>%\n  mutate(`wp_unknown` = lengths(\n    st_intersects(NGA, wp_unknown)))\n\nNotice that four new derived fields have been added into NGA_wp sf data.frame."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex02/in-class_ex02.html#visualizing-attributes-by-using-statistical-graphs",
    "href": "In-Class_Ex/In-Class_Ex02/in-class_ex02.html#visualizing-attributes-by-using-statistical-graphs",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "5.3 Visualizing attributes by using statistical graphs",
    "text": "5.3 Visualizing attributes by using statistical graphs\nIn this code chunk below, appropriate functions of ggplot2 package is used to reveal the distribution of total water points by LGA in histogram.\n\nggplot(data = NGA_wp,\n       aes(x = total_wp)) + \n  geom_histogram(bins=20,\n                 color=\"black\",\n                 fill=\"light blue\") +\n  geom_vline(aes(xintercept=mean(\n    total_wp, na.rm=T)),\n             color=\"red\", \n             linetype=\"dashed\", \n             size=0.8) +\n  ggtitle(\"Distribution of total water points by LGA\") +\n  xlab(\"No. of water points\") +\n  ylab(\"No. of\\nLGAs\") +\n  theme(axis.title.y=element_text(angle = 0))"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex02/in-class_ex02.html#saving-the-analytical-data-in-rds-format",
    "href": "In-Class_Ex/In-Class_Ex02/in-class_ex02.html#saving-the-analytical-data-in-rds-format",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "5.4 Saving the analytical data in rds format",
    "text": "5.4 Saving the analytical data in rds format\nIn order to retain the sf object structure for subsequent analysis, it is recommended to save the sf data.frame into rds format.\nIn the code chunk below, write_rds() of readr package is used to export an sf data.frame into rds format.\n\nwrite_rds(NGA_wp, \"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex03/in-class_ex03.html",
    "href": "In-Class_Ex/In-Class_Ex03/in-class_ex03.html",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "",
    "text": "In this in-class exercise, you will gain hands-on experience on using appropriate R methods to plot analytical maps. For the purpose of this exercise, Nigeria water point data prepared during In-class Exercise 2 will be used.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex03/in-class_ex03.html#installing-and-loading-packages",
    "href": "In-Class_Ex/In-Class_Ex03/in-class_ex03.html#installing-and-loading-packages",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "2.1 Installing and Loading Packages",
    "text": "2.1 Installing and Loading Packages\n\npacman::p_load(tmap, tidyverse, sf)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex03/in-class_ex03.html#importing-data",
    "href": "In-Class_Ex/In-Class_Ex03/in-class_ex03.html#importing-data",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "2.2 Importing Data",
    "text": "2.2 Importing Data\nImporting NGA_wp.rds created in the previous in-class into R environment.\n\nNGA_wp <- read_rds(\"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex03/in-class_ex03.html#visualizing-distribution-of-non-functional-water-point",
    "href": "In-Class_Ex/In-Class_Ex03/in-class_ex03.html#visualizing-distribution-of-non-functional-water-point",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "3.1 Visualizing distribution of non-functional water point",
    "text": "3.1 Visualizing distribution of non-functional water point\nPlot a choropleth map showing the distribution of non-functional water point by LGA\n\np1 <- tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of functional water point by LGAs\",\n            legend.outside = FALSE)\n\n\np2 <- tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of total  water point by LGAs\",\n            legend.outside = FALSE)\n\n\ntmap_arrange(p2, p1, nrow = 1)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex03/in-class_ex03.html#deriving-proportion-of-functional-water-points-and-non-functional-water-points",
    "href": "In-Class_Ex/In-Class_Ex03/in-class_ex03.html#deriving-proportion-of-functional-water-points-and-non-functional-water-points",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "4.1 Deriving Proportion of Functional Water Points and Non-Functional Water Points",
    "text": "4.1 Deriving Proportion of Functional Water Points and Non-Functional Water Points\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nNGA_wp <- NGA_wp %>%\n  mutate(pct_functional = wp_functional/total_wp) %>%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex03/in-class_ex03.html#plotting-map-of-rate",
    "href": "In-Class_Ex/In-Class_Ex03/in-class_ex03.html#plotting-map-of-rate",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "4.2 Plotting map of Rate",
    "text": "4.2 Plotting map of Rate\nPlot a choropleth map showing the distribution of percentage functional water point by LGA\n\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside = TRUE)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex03/in-class_ex03.html#percentile-map",
    "href": "In-Class_Ex/In-Class_Ex03/in-class_ex03.html#percentile-map",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "5.1 Percentile Map",
    "text": "5.1 Percentile Map\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n5.1.1 Data Preparation\nStep 1: Exclude records with NA by using the code chunk below.\n\nNGA_wp <- NGA_wp %>%\n  drop_na()\n\nStep 2: Creating customised classification and extracting values\n\npercent <- c(0,.01,.1,.5,.9,.99,1)\nvar <- NGA_wp[\"pct_functional\"] %>%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n5.1.2 Why Writing Functions?\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\n\n\n5.1.3. Creating the get.var function\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv:vector with values (without a column name)\n\n\n\nget.var <- function(vname,df) {\n  v <- df[vname] %>% \n    st_set_geometry(NULL)\n  v <- unname(v[,1])\n  return(v)\n}\n\n\n\n5.1.4 A percentile mapping function\n\npercentmap <- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent <- c(0,.01,.1,.5,.9,.99,1)\n  var <- get.var(vnam, df)\n  bperc <- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"< 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"> 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\n5.1.5 Test drive the percentile mapping function\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as title, legend positioning just to name a few of them, could be passed to customise various features of the map."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex03/in-class_ex03.html#box-map",
    "href": "In-Class_Ex/In-Class_Ex03/in-class_ex03.html#box-map",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "5.2 Box map",
    "text": "5.2 Box map\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value)\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n5.2.1 Creating the box breaks function\nR Function that creating break points for a box map.\n\narguments:\n\nv:vector with obersations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\nboxbreaks <- function(v,mult=1.5) {\n  qv <- unname(quantile(v))\n  iqr <- qv[4] - qv[2]\n  upfence <- qv[4] + mult * iqr\n  lofence <- qv[2] - mult * iqr\n  # initialize break points vector\n  bb <- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence < qv[1]) {  # no lower outliers\n    bb[1] <- lofence\n    bb[2] <- floor(qv[1])\n  } else {\n    bb[2] <- lofence\n    bb[1] <- qv[1]\n  }\n  if (upfence > qv[5]) { # no upper outliers\n    bb[7] <- upfence\n    bb[6] <- ceiling(qv[5])\n  } else {\n    bb[6] <- upfence\n    bb[7] <- qv[5]\n  }\n  bb[3:5] <- qv[2:4]\n  return(bb)\n}\n\n\n\n5.2.2 Creating the get.var function\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: varaible name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv:vector with values (without a column name)\n\n\n\nget.var <- function(vname,df) {\n  v <- df[vname] %>% st_set_geometry(NULL)\n  v <- unname(v[,1])\n  return(v)\n}\n\n\n\n5.2.3. Test drive the newly created function\n\nvar <- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n5.2.4 Boxmap function\nThe code chunk below is an R function to create a box map. - arguments: - vnam: variable name (as character, in quotes) - df: simple features polygon layer - legtitle: legend title - mtitle: map title - mult: multiplier for IQR - returns: - a tmap-element (plots a map)\n\nboxmap <- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var <- get.var(vnam,df)\n  bb <- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"< 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"> 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nboxmap(\"wp_nonfunctional\", NGA_wp)\n\nWarning: Breaks contains positive and negative values. Better is to use\ndiverging scale instead, or set auto.palette.mapping to FALSE.\n\n\n\n\n\n\n\n5.2.5 Recode zero\nThe code chunk below is used to recode LGAs with zero total water point into NA.\n\nNGA_wp <- NGA_wp %>%\n  mutate(wp_functional = na_if(\n    total_wp, total_wp < 0))"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04/in-class_ex04.html",
    "href": "In-Class_Ex/In-Class_Ex04/in-class_ex04.html",
    "title": "In-class Exercise 4: 4 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "pacman::p_load(maptools, sf, raster, spatstat, tmap)\n\nThings to learn from this code chunk."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04/in-class_ex04.html#handling-duplicated-point-events",
    "href": "In-Class_Ex/In-Class_Ex04/in-class_ex04.html#handling-duplicated-point-events",
    "title": "In-class Exercise 4: 4 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Handling duplicated point events",
    "text": "Handling duplicated point events\n\n\n\n\n\n\nNote\n\n\n\njitter: push the data points apart\nppp: required by spatstat\nowin: confine the study area\n\n\n\nchildcare_ppp_jit <- rjitter(childcare_ppp, retry = TRUE, nsim=1, drop = TRUE)\n\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04/in-class_ex04.html#creating-owin-object",
    "href": "In-Class_Ex/In-Class_Ex04/in-class_ex04.html#creating-owin-object",
    "title": "In-class Exercise 4: 4 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Creating owin object",
    "text": "Creating owin object"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04/in-class_ex04.html#combining-point-events-object-and-owin-object",
    "href": "In-Class_Ex/In-Class_Ex04/in-class_ex04.html#combining-point-events-object-and-owin-object",
    "title": "In-class Exercise 4: 4 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Combining point events object and owin object",
    "text": "Combining point events object and owin object"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/data/stores.html",
    "href": "In-Class_Ex/In-Class_Ex05/data/stores.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     \n\n\n        0 0     false"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/data/study_area.html",
    "href": "In-Class_Ex/In-Class_Ex05/data/study_area.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "Welcome to IS415 Geospatial Analytics and Applications\nThis is the course website of IS415 I study this term. You will find my course work on this website."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "",
    "text": "Water is an important resource to mankind. Clean and accessible water is critical to human health. It provides a healthy environment, a sustainable economy, reduces poverty and ensures peace and security. Yet over 40% of the global population does not have access to sufficient clean water. By 2025, 1.8 billion people will be living in countries or regions with absolute water scarcity, according to UN-Water. The lack of water poses a major threat to several sectors, including food security. Agriculture uses about 70% of the world’s accessible freshwater.\nDeveloping countries are most affected by water shortages and poor water quality. Up to 80% of illnesses in the developing world are linked to inadequate water and sanitation. Despite technological advancement, providing clean water to the rural community is still a major development issues in many countries globally, especially countries in the Africa continent.\nTo address the issue of providing clean and sustainable water supply to the rural community, a global Water Point Data Exchange (WPdx) project has been initiated. The main aim of this initiative is to collect water point related data from rural areas at the water point or small water scheme level and share the data via WPdx Data Repository, a cloud-based data library. What is so special of this project is that data are collected based on WPDx Data Standard."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-spatial-data-analysis-esda",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-spatial-data-analysis-esda",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "3.1 Exploratory Spatial Data Analysis (ESDA)",
    "text": "3.1 Exploratory Spatial Data Analysis (ESDA)\n\nDerive kernel density maps of functional and non-functional water points. Using appropriate tmap functions,\nDisplay the kernel density maps on openstreetmap of Osub State, Nigeria.\nDescribe the spatial patterns revealed by the kernel density maps. Highlight the advantage of kernel density map over point map."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#second-order-spatial-point-patterns-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#second-order-spatial-point-patterns-analysis",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "3.2 Second-order Spatial Point Patterns Analysis",
    "text": "3.2 Second-order Spatial Point Patterns Analysis\nWith reference to the spatial point patterns observed in ESDA:\n\nFormulate the null hypothesis and alternative hypothesis and select the confidence level.\nPerform the test by using appropriate Second order spatial point patterns analysis technique.\nWith reference to the analysis results, draw statistical conclusions."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#spatial-correlation-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#spatial-correlation-analysis",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "3.3 Spatial Correlation Analysis",
    "text": "3.3 Spatial Correlation Analysis\nIn this section, we are required to confirm statistically if the spatial distribution of functional and non-functional water points are independent from each other.\n\nFormulate the null hypothesis and alternative hypothesis and select the confidence level.\nPerform the test by using appropriate Second order spatial point patterns analysis technique.\nWith reference to the analysis results, draw statistical conclusions."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#aspatial-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#aspatial-data",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "4.1 Aspatial data",
    "text": "4.1 Aspatial data\nFor the purpose of this assignment, data from WPdx Global Data Repositories will be used. There are two versions of the data. They are: WPdx-Basic and WPdx+. This take home assignment will use the WPdx+ data set."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#geospatial-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#geospatial-data",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "4.2 Geospatial data",
    "text": "4.2 Geospatial data\nThis study will focus of Osun State, Nigeria. The state boundary GIS data of Nigeria can be downloaded either from The Humanitarian Data Exchange portal or geoBoundaries."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/in-class_ex05.html",
    "href": "In-Class_Ex/In-Class_Ex05/in-class_ex05.html",
    "title": "in-class_ex05",
    "section": "",
    "text": "pacman:: p_load(tidyverse, tmap, sf ,sfdep)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/in-class_ex05.html#visualising-the-sf-layers",
    "href": "In-Class_Ex/In-Class_Ex05/in-class_ex05.html#visualising-the-sf-layers",
    "title": "in-class_ex05",
    "section": "Visualising the sf layers",
    "text": "Visualising the sf layers\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(studyArea) + \n  tm_polygons() +\ntm_shape(stores)+\n  tm_dots(col = \"Name\",\n          size = 0.01,\n          border.col = \"black\",\n          border.lwd = 0.5) +\n  tm_view(set.zoom.limits = c(12,16))\n\n\n\n\n\n\n\nnb <- include_self(\n  st_knn(st_geometry(stores),6))\n\n\nwt <- st_kernel_weights(nb,\n                        stores,\n                        \"gaussian\",\n                        adaptive = TRUE)\n\n\nFamilyMart <- stores %>%\n  filter(Name == \"Family Mart\")\nA <- FamilyMart$Name\n\n\nSevenEleven <- stores %>%\n  filter(Name == \"7-Eleven\")\nB <- SevenEleven$Name\n\n\nLCLQ <- local_colocation(A, B, nb, wt, 49)\n\n\nLCLQ_stores <- cbind(stores, LCLQ)\n\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(studyArea) +\n  tm_polygons() + \ntm_shape(LCLQ_stores) +\n  tm_dots(col = \"X7.Eleven\",\n          size = 0.01,\n          border.col = \"black\",\n          border.lwd = 0.5) +\n  tm_view(set.zoom.limits = c(12,16))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#install-and-load-packages",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#install-and-load-packages",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "5.1 Install and Load Packages",
    "text": "5.1 Install and Load Packages\n\npacman::p_load(funModeling, maptools, tidyverse, sf, sfdep, raster, spatstat, tmap)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-geospatial-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-geospatial-data",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "Importing Geospatial Data",
    "text": "Importing Geospatial Data\n\ngeoboundaries <- st_read(dsn = \"data/geospatial\", layer=\"geoBoundaries-NGA-ADM2\") %>%\n  st_transform(crs = 26392)\n\nReading layer `geoBoundaries-NGA-ADM2' from data source \n  `C:\\HoYongQuan\\IS415-GAA(New)\\Take-home_Ex\\Take-home_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-aspatial-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-aspatial-data",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "Importing Aspatial Data",
    "text": "Importing Aspatial Data\n\nWaterpoint =  read_csv(\"data/aspatial/Water_Point_Data_Exchange_-_Plus__WPdx__.csv\") %>% \n  filter(`#clean_country_name` == \"Nigeria\")\n\n3.2.1 Converting Aspatial Data into Geospatial\nThis process involves two steps.\nFirst, there is a need to convert the well known text field into sfc field by using st_as_sfc\n\nWaterpoint$Geometry = st_as_sfc(Waterpoint$`New Georeferenced Column`)\nWaterpoint\n\n# A tibble: 97,478 × 75\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n    <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 158721 Federal Minis…    5.07    6.62 02/19/… Yes     Boreho… Well    Mechan…\n 2 158892 Federal Minis…    5.09    7.09 02/06/… Yes     Boreho… Well    Hand P…\n 3 323117 Federal Minis…    5.91    8.77 08/31/… Yes     Boreho… Well    Hand P…\n 4 300176 Federal Minis…    5.23    7.32 05/17/… Yes     Boreho… Well    Mechan…\n 5 324346 Federal Minis…    6.88    3.36 08/17/… Yes     Boreho… Well    Mechan…\n 6 297273 Federal Minis…    6.59    3.29 05/26/… Yes     Boreho… Well    Mechan…\n 7 296853 Federal Minis…    6.60    3.26 06/02/… Yes     Boreho… Well    Mechan…\n 8 323866 Federal Minis…    6.20    6.73 09/18/… Yes     Boreho… Well    Mechan…\n 9 297044 Federal Minis…    6.61    3.30 05/26/… Yes     Boreho… Well    Mechan…\n10 324321 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n# … with 97,468 more rows, 66 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\nSecondly, we will convert the tibble data.frame into an sf object by using st_sf().\n\nWaterpoint_sf <- st_sf(Waterpoint, crs = 4326)\nWaterpoint_sf\n\nSimple feature collection with 97478 features and 74 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 2.707441 ymin: 4.301812 xmax: 14.21828 ymax: 13.86568\nGeodetic CRS:  WGS 84\n# A tibble: 97,478 × 75\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n *  <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 158721 Federal Minis…    5.07    6.62 02/19/… Yes     Boreho… Well    Mechan…\n 2 158892 Federal Minis…    5.09    7.09 02/06/… Yes     Boreho… Well    Hand P…\n 3 323117 Federal Minis…    5.91    8.77 08/31/… Yes     Boreho… Well    Hand P…\n 4 300176 Federal Minis…    5.23    7.32 05/17/… Yes     Boreho… Well    Mechan…\n 5 324346 Federal Minis…    6.88    3.36 08/17/… Yes     Boreho… Well    Mechan…\n 6 297273 Federal Minis…    6.59    3.29 05/26/… Yes     Boreho… Well    Mechan…\n 7 296853 Federal Minis…    6.60    3.26 06/02/… Yes     Boreho… Well    Mechan…\n 8 323866 Federal Minis…    6.20    6.73 09/18/… Yes     Boreho… Well    Mechan…\n 9 297044 Federal Minis…    6.61    3.30 05/26/… Yes     Boreho… Well    Mechan…\n10 324321 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n# … with 97,468 more rows, 66 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\nTransforming the Waterpoint sf object into Nigeria Projected coordinate system\n\nWaterpoint_sf <- Waterpoint_sf %>%\n  st_transform(crs = 26392)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-data",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "5.2 Importing Data",
    "text": "5.2 Importing Data\n\n5.2.1 Geospatial Data\n\n5.2.1.1 Reading GeoBoundaries Data Set\n\ngeoNGA <- st_read(dsn = \"data/geospatial\", layer=\"geoBoundaries-NGA-ADM2\") %>%\n  st_transform(crs = 26392)\n\nReading layer `geoBoundaries-NGA-ADM2' from data source \n  `C:\\HoYongQuan\\IS415-GAA(New)\\Take-home_Ex\\Take-home_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\n\n\n5.2.1.2 Reading NGA Data Set\n\nNGA <- st_read(\"data/geospatial/\",\n               layer = \"nga_admbnda_adm2_osgof_20190417\") %>%\n  st_transform(crs = 26392)\n\nReading layer `nga_admbnda_adm2_osgof_20190417' from data source \n  `C:\\HoYongQuan\\IS415-GAA(New)\\Take-home_Ex\\Take-home_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\n\n\n\n5.2.2 Aspatial Data\n\n5.2.2.1 Reading WPdx+ Data Set\n\nWaterpoint =  read_csv(\"data/aspatial/Water_Point_Data_Exchange_-_Plus__WPdx__.csv\") %>% \n  filter(`#clean_country_name` == \"Nigeria\")\n\n\n\n5.2.2.2 Converting the Aspatial Data into sf point features\nThis process involves two steps.\nFirst, there is a need to convert the well known text field into sfc field by using st_as_sfc\n\nWaterpoint$Geometry = st_as_sfc(Waterpoint$`New Georeferenced Column`)\nWaterpoint\n\n# A tibble: 97,478 × 75\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n    <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 158721 Federal Minis…    5.07    6.62 02/19/… Yes     Boreho… Well    Mechan…\n 2 158892 Federal Minis…    5.09    7.09 02/06/… Yes     Boreho… Well    Hand P…\n 3 323117 Federal Minis…    5.91    8.77 08/31/… Yes     Boreho… Well    Hand P…\n 4 300176 Federal Minis…    5.23    7.32 05/17/… Yes     Boreho… Well    Mechan…\n 5 324346 Federal Minis…    6.88    3.36 08/17/… Yes     Boreho… Well    Mechan…\n 6 297273 Federal Minis…    6.59    3.29 05/26/… Yes     Boreho… Well    Mechan…\n 7 296853 Federal Minis…    6.60    3.26 06/02/… Yes     Boreho… Well    Mechan…\n 8 323866 Federal Minis…    6.20    6.73 09/18/… Yes     Boreho… Well    Mechan…\n 9 297044 Federal Minis…    6.61    3.30 05/26/… Yes     Boreho… Well    Mechan…\n10 324321 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n# … with 97,468 more rows, 66 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\nSecondly, we will convert the tibble data.frame into an sf object by using st_sf(). Afterwhich, we run “Waterpoint_sf” to check if the data.frame is converted into an sf object.\n\nWaterpoint_sf <- st_sf(Waterpoint, crs = 4326)\nWaterpoint_sf\n\nSimple feature collection with 97478 features and 74 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 2.707441 ymin: 4.301812 xmax: 14.21828 ymax: 13.86568\nGeodetic CRS:  WGS 84\n# A tibble: 97,478 × 75\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n *  <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 158721 Federal Minis…    5.07    6.62 02/19/… Yes     Boreho… Well    Mechan…\n 2 158892 Federal Minis…    5.09    7.09 02/06/… Yes     Boreho… Well    Hand P…\n 3 323117 Federal Minis…    5.91    8.77 08/31/… Yes     Boreho… Well    Hand P…\n 4 300176 Federal Minis…    5.23    7.32 05/17/… Yes     Boreho… Well    Mechan…\n 5 324346 Federal Minis…    6.88    3.36 08/17/… Yes     Boreho… Well    Mechan…\n 6 297273 Federal Minis…    6.59    3.29 05/26/… Yes     Boreho… Well    Mechan…\n 7 296853 Federal Minis…    6.60    3.26 06/02/… Yes     Boreho… Well    Mechan…\n 8 323866 Federal Minis…    6.20    6.73 09/18/… Yes     Boreho… Well    Mechan…\n 9 297044 Federal Minis…    6.61    3.30 05/26/… Yes     Boreho… Well    Mechan…\n10 324321 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n# … with 97,468 more rows, 66 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\n\n\n5.2.2.3 Transforming the Waterpoint sf object into Nigeria Projected Coordinate System\n\nWaterpoint_sf <- Waterpoint_sf %>%\n  st_transform(crs = 26392)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#excluding-redundant-fields",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#excluding-redundant-fields",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "6.1 Excluding Redundant Fields",
    "text": "6.1 Excluding Redundant Fields\n\nNGA <- NGA %>%\n   dplyr::select(c(3:4, 8:9))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#checking-for-duplicated-fields-in-the-geospatial-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#checking-for-duplicated-fields-in-the-geospatial-data",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "6.2 Checking for duplicated fields in the Geospatial Data",
    "text": "6.2 Checking for duplicated fields in the Geospatial Data\n\nNGA$ADM2_EN[duplicated(NGA$ADM2_EN)==TRUE]\n\n[1] \"Bassa\"    \"Ifelodun\" \"Irepodun\" \"Nasarawa\" \"Obi\"      \"Surulere\"\n\n\nThe output above shows that there are 6 LGAs with the same name. However, there are LGAs with the same name but they are located in different states.\n\nNGA$ADM2_EN[94] <- \"Bassa, Kogi\"\nNGA$ADM2_EN[95] <- \"Bassa, Plateau\"\nNGA$ADM2_EN[304] <- \"Ifelodun, Kwara\"\nNGA$ADM2_EN[305] <- \"Ifelodun, Osun\"\nNGA$ADM2_EN[355] <- \"Irepodun, Kwara\"\nNGA$ADM2_EN[356] <- \"Irepodun, Osun\"\nNGA$ADM2_EN[519] <- \"Nasarawa, Kano\"\nNGA$ADM2_EN[520] <- \"Nasarawa, Nasarawa\"\nNGA$ADM2_EN[546] <- \"Obi, Benue\"\nNGA$ADM2_EN[547] <- \"Obi, Nasarawa\"\nNGA$ADM2_EN[693] <- \"Surulere, Lagos\"\nNGA$ADM2_EN[694] <- \"Surulere, Oyo\"\n\nTo check if there are still duplicate names after replacing them in the above code chunk.\n\nNGA$ADM2_EN[duplicated(NGA$ADM2_EN)==TRUE]\n\ncharacter(0)\n\n\nFrom the above result, “character(0)” represents no duplicated names."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#extracting-water-point-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#extracting-water-point-data",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "7.1 Extracting Water Point Data",
    "text": "7.1 Extracting Water Point Data\nThe code chunk below is used to extract functional water point\n\nWaterpoint_functional <- Waterpoint_sf_nga %>%\n  filter(status_clean %in%\n            c(\"Functional\",\n              \"Functional, needs repair\",\n              \"Functional, not in use\",\n             \"Functional but not in use\",\n             \"Functional but needs repair\"))\n\nThe code chunk below is used to extract non-functional water point\n\nWaterpoint_nonfunctional <-  Waterpoint_sf_nga %>%\n  filter(status_clean %in%\n           c(\"Abandoned/Decommissioned\",\n             \"Non-Functional due to dry season\",\n             \"Non-Functional\",\n             \"Non-Functional, dry\"))\n\nThe code chunk below is used to extract the water point with unknown status\n\nWaterpoint_unknown <- Waterpoint_sf_nga %>%\n  filter(status_clean == \"unknown\")\n\nThe code chunk below is used to perform a quick Exploratory Data Analysis (EDA) on the derived sf data frames for the Functional, Non-functional & Unknown Waterpoints.\n\nfunModeling::freq(data = Waterpoint_functional,\n     input = 'status_clean')\n\n\n\n\n                 status_clean frequency percentage cumulative_perc\n1                  Functional     47228      87.65           87.65\n2    Functional, needs repair      4792       8.89           96.54\n3      Functional, not in use      1775       3.29           99.83\n4   Functional but not in use        86       0.16           99.99\n5 Functional but needs repair         4       0.01          100.00\n\n\n\nfunModeling::freq(data = Waterpoint_nonfunctional,\n     input = 'status_clean')\n\n\n\n\n                      status_clean frequency percentage cumulative_perc\n1                   Non-Functional     30638      91.62           91.62\n2              Non-Functional, dry      2473       7.40           99.02\n3         Abandoned/Decommissioned       321       0.96           99.98\n4 Non-Functional due to dry season         7       0.02          100.00\n\n\n\nfunModeling::freq(data = Waterpoint_unknown,\n     input = 'status_clean')\n\n\n\n\n  status_clean frequency percentage cumulative_perc\n1      unknown     10154        100             100"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performing-point-in-polygon-count",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performing-point-in-polygon-count",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "7.2 Performing Point-in-Polygon Count",
    "text": "7.2 Performing Point-in-Polygon Count\n\nNGA_wp <- NGA %>% \n  mutate(`total_wp` = lengths(\n    st_intersects(NGA, Waterpoint_sf_nga))) %>%\n  mutate(`wp_functional` = lengths(\n    st_intersects(NGA, Waterpoint_functional))) %>%\n  mutate(`wp_nonfunctional` = lengths(\n    st_intersects(NGA, Waterpoint_nonfunctional))) %>%\n  mutate(`wp_unknown` = lengths(\n    st_intersects(NGA, Waterpoint_unknown)))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualizing-attributes-by-using-statistical-graphs",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualizing-attributes-by-using-statistical-graphs",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "7.3 Visualizing Attributes by using statistical graphs",
    "text": "7.3 Visualizing Attributes by using statistical graphs\n\nggplot(data = NGA_wp,\n       aes(x = total_wp)) + \n  geom_histogram(bins=20,\n                 color=\"black\",\n                 fill=\"light blue\") +\n  geom_vline(aes(xintercept=mean(\n    total_wp, na.rm=T)),\n             color=\"red\", \n             linetype=\"dashed\", \n             size=0.8) +\n  ggtitle(\"Distribution of total water points by LGA\") +\n  xlab(\"No. of water points\") +\n  ylab(\"No. of\\nLGAs\") +\n  theme(axis.title.y=element_text(angle = 0))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#saving-the-analytical-data-in-rds-format",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#saving-the-analytical-data-in-rds-format",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "7.4 Saving the Analytical Data in RDS format",
    "text": "7.4 Saving the Analytical Data in RDS format\nIn order to retain the sf object structure for subsequent analysis, it is recommended to save the sf data.frame into rds format.\n\nwrite_rds(NGA_wp, \"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#showing-the-functional-waterpoints-in-osun-state",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#showing-the-functional-waterpoints-in-osun-state",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "8.1 Showing the Functional Waterpoints in Osun State",
    "text": "8.1 Showing the Functional Waterpoints in Osun State\n\ntm_shape(osun_data) +\n  tm_fill(\"wp_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#showing-the-non-functional-water-points-in-osun-state",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#showing-the-non-functional-water-points-in-osun-state",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "8.2 Showing the Non-functional water points in Osun State",
    "text": "8.2 Showing the Non-functional water points in Osun State\n\ntm_shape(osun_data) +\n  tm_fill(\"wp_nonfunctional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\")\n\n\n\n\nComparing the two graphs plotted, we can see that, there are more Non-functional water points in Osun."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-osun_data-sf-dataframe-to-sps-spatial-class",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-osun_data-sf-dataframe-to-sps-spatial-class",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "9.1 Converting Osun_data sf Dataframe to sp’s Spatial* class",
    "text": "9.1 Converting Osun_data sf Dataframe to sp’s Spatial* class\n\nosun <- as_Spatial(osun_data)\n\n\nfunctional <- as_Spatial(Waterpoint_functional)\n\n\nnonfunctional <- as_Spatial(Waterpoint_nonfunctional)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-the-spatial-class-into-generic-sp-format",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-the-spatial-class-into-generic-sp-format",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "9.2 Converting the Spatial* class into Generic sp Format",
    "text": "9.2 Converting the Spatial* class into Generic sp Format\n\nosun_sp <- as(osun, \"SpatialPolygons\")\n\n\nfunctional_sp <- as(functional, \"SpatialPoints\")\n\n\nnonfunctional_sp <- as(nonfunctional, \"SpatialPoints\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "9.3 Converting the Generic sp Format into Spatstat’s ppp Format",
    "text": "9.3 Converting the Generic sp Format into Spatstat’s ppp Format\n\nfunctional_ppp <- as(functional_sp, \"ppp\")\nfunctional_ppp\n\nPlanar point pattern: 53885 points\nwindow: rectangle = [29322.6, 1293137] x [33758.4, 1092628.9] units\n\n\n\nnonfunctional_ppp <- as(nonfunctional_sp, \"ppp\")\nnonfunctional_ppp\n\nPlanar point pattern: 33439 points\nwindow: rectangle = [28907.9, 1293292.9] x [33736.9, 1092882.6] units\n\n\n\nplot(functional_ppp)\n\n\n\n\n\nplot(nonfunctional_ppp)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#handling-duplicated-points-for-functional_ppp-and-nonfunctional_ppp",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#handling-duplicated-points-for-functional_ppp-and-nonfunctional_ppp",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "9.4 Handling Duplicated Points for Functional_ppp and Nonfunctional_ppp",
    "text": "9.4 Handling Duplicated Points for Functional_ppp and Nonfunctional_ppp\n\nfunctional_ppp_jit <- rjitter(functional_ppp,\n                              retry=TRUE,\n                              nsim=1,\n                              drop=TRUE)\n\n\nnonfunctional_ppp_jit <- rjitter(nonfunctional_ppp,\n                              retry=TRUE,\n                              nsim=1,\n                              drop=TRUE)\n\nChecking for if there are any duplicated points after rjitter function\n\nany(duplicated(functional_ppp_jit))\n\n[1] FALSE\n\n\n\nany(duplicated(nonfunctional_ppp_jit))\n\n[1] FALSE"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#creating-osun-owin-object",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#creating-osun-owin-object",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "9.5 Creating Osun owin Object",
    "text": "9.5 Creating Osun owin Object\n\nosun_owin <- as(osun_sp, \"owin\")\n\nDisplaying Osun Boundary created\n\nplot(osun_owin)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#combining-point-events-object-and-owin-object",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#combining-point-events-object-and-owin-object",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "9.6 Combining Point Events Object and owin Object",
    "text": "9.6 Combining Point Events Object and owin Object\n\nfunctionalOsun_ppp_jit = functional_ppp_jit[osun_owin]\n\n\nnonfunctionalOsun_ppp_jit = nonfunctional_ppp_jit[osun_owin]\n\nDisplaying Functional Waterpoints in Osun State\n\nplot(functionalOsun_ppp_jit)\n\n\n\n\nDisplaying Non-Functional Waterpoints in Osun State\n\nplot(nonfunctionalOsun_ppp_jit)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#rescaling-kde-values",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#rescaling-kde-values",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "10.1 Rescaling KDE Values",
    "text": "10.1 Rescaling KDE Values\n\nfunctionalOsun_ppp.km <- rescale(functionalOsun_ppp_jit, 1000, \"km\")\n\n\nnonfunctionalOsun_ppp.km <- rescale(functionalOsun_ppp_jit, 1000, \"km\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#kernel-density-estimation",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#kernel-density-estimation",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "10.2 Kernel Density Estimation",
    "text": "10.2 Kernel Density Estimation\n\n10.2.1 Kernel Density Map for Functional Waterpoints in Osun\n\nkde_functionalOsun_bw <- density(functionalOsun_ppp.km,\n                                 sigma=bw.ppl,\n                                 edge=TRUE,\n                                 kernel=\"gaussian\")\nplot(kde_functionalOsun_bw)\n\n\n\n\n\n\n10.2.2 Kernel Density Map for Non-functional Waterpoints in Osun\n\nkde_nonfunctionalOsun_bw <- density(nonfunctionalOsun_ppp.km,\n                                 sigma=bw.ppl,\n                                 edge=TRUE,\n                                 kernel=\"gaussian\")\nplot(kde_nonfunctionalOsun_bw)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-kde-output-into-grid-object",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-kde-output-into-grid-object",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "10.3 Converting KDE Output into Grid Object",
    "text": "10.3 Converting KDE Output into Grid Object\n\nkde_functionalOsun_bw_raster <- kde_functionalOsun_bw %>% as.SpatialGridDataFrame.im() %>% raster()\nkde_functionalOsun_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -5.813911e-16, 11.91494  (min, max)\n\n\n\nprojection(kde_functionalOsun_bw_raster) <- CRS(\"+init=EPSG:26392 +datum=WGS84 +units=km\")\nkde_functionalOsun_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +units=km +no_defs \nsource     : memory\nnames      : v \nvalues     : -5.813911e-16, 11.91494  (min, max)\n\n\n\ntmap_mode(\"view\") +\n  tm_shape(kde_functionalOsun_bw_raster) + \n  tm_basemap(\"OpenStreetMap\") +\n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#kernel-density-maps-vs-point-map",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#kernel-density-maps-vs-point-map",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "10.4 Kernel Density Maps Vs Point Map",
    "text": "10.4 Kernel Density Maps Vs Point Map\n\n10.4.1 Importing and Filtering of Data for Point Map\n\nwp_nga_filter <- read_csv(\"data/aspatial/Water_Point_Data_Exchange_-_Plus__WPdx__.csv\")\n\n\nwp_nga_filter <- wp_nga_filter %>% \n  rename(clean_adm1 = '#clean_adm1')\n\n\nwp_nga_filter <- wp_nga_filter %>% \n  rename(status_clean = '#status_clean')\n\n\nwp_nga_filter <- subset(wp_nga_filter, clean_adm1 == \"Osun\")\n\n\nwp_nga_filter$Geometry = st_as_sfc(wp_nga_filter$`New Georeferenced Column`)\nwp_nga_filter\n\n# A tibble: 5,745 × 75\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n    <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 225950 Federal Minis…    7.43    4.26 05/05/… Yes     Boreho… Well    Hand P…\n 2 225524 Federal Minis…    7.78    4.56 04/22/… Yes     Protec… Well    Hand P…\n 3 197014 Federal Minis…    7.49    4.53 04/30/… Yes     Boreho… Well    Mechan…\n 4 225173 Federal Minis…    7.93    4.73 05/02/… Yes     Boreho… Well    Hand P…\n 5 225843 Federal Minis…    7.74    4.44 05/08/… Yes     Boreho… Well    Hand P…\n 6 235508 Federal Minis…    7.15    4.64 04/27/… Yes     Protec… Well    Hand P…\n 7 197708 Federal Minis…    7.87    4.72 05/13/… Yes     Boreho… Well    Mechan…\n 8 195041 Federal Minis…    7.73    4.45 06/17/… Yes     Protec… Spring  <NA>   \n 9 225222 Federal Minis…    7.81    4.15 05/14/… Yes     Protec… Spring  Mechan…\n10 460770 GRID3             7.4     4.33 06/13/… Unknown Boreho… Well    <NA>   \n# … with 5,735 more rows, 66 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, clean_adm1 <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, status_clean <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\n\nwp_nga_filter <- st_sf(wp_nga_filter, crs=4326)\nwp_nga_filter\n\nSimple feature collection with 5745 features and 74 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 4.032004 ymin: 7.060309 xmax: 5.06 ymax: 8.061898\nGeodetic CRS:  WGS 84\n# A tibble: 5,745 × 75\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n *  <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 225950 Federal Minis…    7.43    4.26 05/05/… Yes     Boreho… Well    Hand P…\n 2 225524 Federal Minis…    7.78    4.56 04/22/… Yes     Protec… Well    Hand P…\n 3 197014 Federal Minis…    7.49    4.53 04/30/… Yes     Boreho… Well    Mechan…\n 4 225173 Federal Minis…    7.93    4.73 05/02/… Yes     Boreho… Well    Hand P…\n 5 225843 Federal Minis…    7.74    4.44 05/08/… Yes     Boreho… Well    Hand P…\n 6 235508 Federal Minis…    7.15    4.64 04/27/… Yes     Protec… Well    Hand P…\n 7 197708 Federal Minis…    7.87    4.72 05/13/… Yes     Boreho… Well    Mechan…\n 8 195041 Federal Minis…    7.73    4.45 06/17/… Yes     Protec… Spring  <NA>   \n 9 225222 Federal Minis…    7.81    4.15 05/14/… Yes     Protec… Spring  Mechan…\n10 460770 GRID3             7.4     4.33 06/13/… Unknown Boreho… Well    <NA>   \n# … with 5,735 more rows, 66 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, clean_adm1 <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, status_clean <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\n\nwp_nga_filter <- wp_nga_filter %>%\n  st_transform(crs = 26392)\n\n\nwp_nga_filterpoint <- wp_nga_filter %>%\n  filter(status_clean == \"Functional\" | status_clean == \"Functional but not in use\" | status_clean == \"Functional but needs repair\" | status_clean ==     \"Functional, needs repair\" | status_clean == \"Functional, not in use\")\n\n\n\n10.4.2 Display Point Map for Functional Waterpoints\n\nwp_nga_filter_point <- tmap_mode(\"view\")\n  tm_shape(wp_nga_filterpoint) +\n  tm_dots(col = \"status_clean\",\n             size = 0.01,\n             border.col = \"black\",\n             border.lwd = 0.5) +\n  tm_view(set.zoom.limits = c(9,11))\n\n\n\n\n\n\n10.4.3 Display Kernel Density Map for Functional Waterpoints\n\nplot(kde_functionalOsun_bw)\n\n\n\n\n\n\n\n\n\n\nAdvantages of Kernel Density Map Over Point Map\n\n\n\n\nKernel density maps smooth out the data, making it easier to see patterns and trends in the data. This is useful for detecting areas with high concentrations of data points.\nIf point maps are cluttered, it can be difficult to interpret when there are many data points in a small area. Thus, kernel density maps help to mitigate this problem by aggregating the data into a continuous surface making it easier to visualize the patterns.\nKernel density maps can show the density of data points in a particular area which point map is unable to do so.\nKernel density maps can also better represent the spatial relationships between data points such as promixity, distance and clustering."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#preparing-nearest-neighbour",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#preparing-nearest-neighbour",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "12.1 Preparing Nearest Neighbour",
    "text": "12.1 Preparing Nearest Neighbour\n\nwaterpoint_sf_osun <- Waterpoint_sf %>% \n  rename(status_clean = '#status_clean') %>%\n  rename(lat = '#lat_deg') %>%\n  rename(lng = '#lon_deg') %>%\n  rename(clean_adm1 = '#clean_adm1') %>%\n  mutate(status_clean = replace_na(\n    status_clean, \"unknown\"))\n\n\nwaterpoint_sf_osunfilter <- subset(waterpoint_sf_osun, clean_adm1 == \"Osun\")\n\n\nwaterpoint_sf_osunfilter <- waterpoint_sf_osunfilter %>%\n  dplyr::select(status_clean, lat, lng)\n\n\nnb <- include_self(\n  st_knn(st_geometry(waterpoint_sf_osunfilter), 6))\n\n\nwt <- st_kernel_weights(nb, \n                        waterpoint_sf_osunfilter, \n                        \"gaussian\", \n                        adaptive = TRUE)\n\n\nfunctionalWaterpoint <- waterpoint_sf_osunfilter %>%\n  filter(status_clean %in%\n           c(\"Functional\",\n             \"Functional but not in use\",\n             \"Functional but needs repair\",\n             \"Functional, needs repair\",\n             \"Functional, not in use\"))\nA <- functionalWaterpoint$status_clean\n\n\nnonfunctionalWaterpoint <- waterpoint_sf_osunfilter %>%\n  filter(status_clean %in%\n           c(\"Abandoned/Decommissioned\",\n             \"Non-Functional due to dry season\",\n             \"Non-Functional\",\n             \"Non-functional, dry\"))\nB <- nonfunctionalWaterpoint$status_clean\n\n\nLCLQ <- local_colocation(A, B, nb, wt, 39)\n\n\nLCLQ_WP <- cbind(waterpoint_sf_osunfilter, LCLQ)\n\n\ntmap_mode(\"view\")\ntm_shape(LCLQ_WP)+ \n  tm_dots(col = \"Non.Functional\",\n             size = 0.01,\n             border.col = \"black\",\n             border.lwd = 0.5) +\n  tm_view(set.zoom.limits = c(9, 16))\n\n\n\n\n\n\nKernel Density Map with Open Street Map"
  }
]