---
title: "in-class_ex07"
---

Installing and Loading the R Packages

Four R Packages will be used for this in-class exercise, they are: sf, sfdep, tmap and tidyverse

```{r}
pacman::p_load(sf, tmap, sfdep, tidyverse, zoo)
```

# The Data

For the purpose of this in-class exericse, the Human data sets will be used.

There are two data sets in this use case, they are:

-   Hunan, a geospatial data set in ESRI shapefile format, and

-   Hunan_2021, an attribute data set in csv format.

## Importing geospatial data

```{r}
hunan <- st_read(dsn ="data/geospatial", 
                 layer = "Hunan")

#contiguity can use this dataset, because of geographic coordinate system.
```

## Importing attribute table

```{r}
hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv")

#didnt load readr in pacman, because this package is part of tidyverse
```

## Combining both data frame by using left join

::: callout-important
## Important

In order to retain the geospatial properties, the left data frame must be the sf data.frame (i.e. hunan)
:::

```{r}
hunan_GDPPC <- left_join(hunan, hunan2012)%>%
  select(1:4, 7, 15)
#retain column 1 to 4, 7 and 15
```

# Plotting Choropleth Map

```{r}
tmap_mode("plot")
tm_shape(hunan_GDPPC) +
  tm_fill("GDPPC",
          style = "quantile",
          palette = "Blues",
          title = "GDPPC") +
  tm_layout(main.title = "Distribution of GDP per capita by district, Hunan Province",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45,
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 2) + 
  tm_scale_bar() +
  tm_grid(alpha = 0.2)

#Classification: Regional Economics, Equal interval range
```

# Global  Measures of Spatial Association

## Step 1: Deriving Contiguity weights: Queen's method

Deriving contiguity weights: Queen's method

In the code chunk below, queen method is used to derive the contiguity weights.

```{r}
wm_q <- hunan_GDPPC %>%
  mutate(nb = st_contiguity(geometry),
         wt = st_weights(nb,
                         style = "W",),
         .before = 1)
```

```{r}
wm_q
```

## Computing Global Moran's I

In the code chunk below, global_moran() function is used to compute the Moran\'s I value. Different from spdep package, the output is a tibble data.frame.

```{r}
moranI <- global_moran(wm_q$GDPPC,
                       wm_q$nb,
                       wm_q$wt)
```

## Performing Global Moran's I test

In general, Moran\'s I test will be performed instead of just computing the Moran\'s I statistics. With sfdep package, Moran\'s I test can be performed by using [`global_moran_test()`](https://sfdep.josiahparry.com/reference/global_moran_test.html) as shown in the code chunk below.

```{r}
global_moran_test(wm_q$GDPPC,
                  wm_q$nb,
                  wm_q$wt)
```

## Performing Global Moran I's permutation test

In practice, monte carlo simulation should be used to perform the statistical test. For **sfdep**, it is supported by [`globel_moran_perm()`](https://sfdep.josiahparry.com/reference/global_moran_perm.html)

It is alway a good practice to use `set.seed()` before performing simulation. This is to ensure that the computation is reproducible.

reject null hypothesis that gdp per capita is spatial dependence because p value is \< 1

If moran I statistics value is negative then the alternative hypothesis is lesser than

```{r}
#needed for simulation to ensure same result
set.seed(1234)

global_moran_perm(wm_q$GDPPC,
                  wm_q$nb,
                  wm_q$wt,
                  nsim = 99)
```

The report above show that the p-value is smaller than alpha value of 0.05. Hence, reject the null hypothesis that the spatial patterns spatial independent. Because the Moran\'s I statistics is greater than 0. We can infer the spatial distribution shows sign of clustering.

# Computing local Moran's I

In this section, you will learn how to compute Local Moran\'s I of GDPPC at county level by using [`local_moran()`](https://sfdep.josiahparry.com/reference/local_moran.html) of sfdep package.

```{r}
lisa <- wm_q %>%
  mutate(local_moran = local_moran(
    GDPPC, nb, wt, nsim=99),
    .before = 1) %>%
  unnest(local_moran)
lisa
```

## Visualising local Moran's I

In this code chunk below, tmap functions are used prepare a choropleth map by using value in the *ii* field.

```{r}
tmap_mode("plot")
tm_shape(lisa) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of GDPPC",
            main.title.size = 0.8)
```

## Visualising p-value of local moran's I

In the code chunk below, tmap functions are used prepare a choropleth map by using value in the *p_ii_sim* field.

```{r}
tmap_mode("plot")
tm_shape(lisa) +
  tm_fill("p_ii_sim") + 
  tm_borders(alpha = 0.5) +
   tm_layout(main.title = "p-value of local Moran's I",
            main.title.size = 0.8)
```

## Visualising local Moran's I and p-value

For effective comparison, it will be better for us to plot both maps next to each other as shown below.

```{r}
tmap_mode("plot")
map1 <- tm_shape(lisa) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of GDPPC",
            main.title.size = 0.8)

map2 <- tm_shape(lisa) +
  tm_fill("p_ii",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I",
            main.title.size = 0.8)

tmap_arrange(map1, map2, ncol = 2)
```

## Visualising LISA Map

LISA map is a categorical map showing outliers and clusters. There are two types of outliers namely: High-Low and Low-High outliers. Likewise, there are two type of clusters namely: High-High and Low-Low cluaters. In fact, LISA map is an interpreted map by combining local Moran\'s I of geographical areas and their respective p-values.

In lisa sf data.frame, we can find three fields contain the LISA categories. They are *mean*, *median* and *pysal*. In general, classification in *mean* will be used as shown in the code chunk below.

```{r}
lisa_sig <- lisa  %>%
  filter(p_ii < 0.05)
tmap_mode("plot")
tm_shape(lisa) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_sig) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4)
```

# Hotspot and Cold Spot Area Analysis (HCSA)

HCSA uses spatial weights to identify locations of statistically significant hot spots and cold spots in an spatially weighted attribute that are in proximity to one another based on a calculated distance. The analysis groups features when similar high (hot) or low (cold) values are found in a cluster. The polygon features usually represent administration boundaries or a custom grid structure.

## Computing local Gi\* statistics

```{r}
wm_idw <- hunan_GDPPC %>%
  mutate(nb = st_contiguity(geometry),
         wts = st_inverse_distance(nb, geometry,
                                   scale = 1,
                                   alpha = 1),
         .before = 1)
```

```{r}
HCSA <- wm_idw %>% 
  mutate(local_Gi = local_gstar_perm(
    GDPPC, nb, wt, nsim = 99),
         .before = 1) %>%
  unnest(local_Gi)
HCSA
```

Local g has ii=0

generally we will use g\*

## Visualising Gi\*

```{r}
tmap_mode("view")
tm_shape(HCSA) +
  tm_fill("gi_star") +
  tm_borders(alpha=0.5) +
  tm_view(set.zoom.limits = c(6,8))
```

## Visualising p-value of HCSA

```{r}
tmap_mode("plot")
tm_shape(HCSA) + 
  tm_fill("p_sim") + 
  tm_borders(alpha = 0.5)
```

## Visualising local HCSA

For effective comparison, you can plot both maps next to each other as shown below.

```{r}
tmap_mode("plot")
map1 <- tm_shape(HCSA) +
  tm_fill("gi_star") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "Gi* of GDPPC",
            main.title.size = 0.8)

map2 <- tm_shape(HCSA) +
  tm_fill("p_value",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of Gi*",
            main.title.size = 0.8)

tmap_arrange(map1, map2, ncol = 2)
```

## Visualising hotspot and cold spot areas 

Now, we are ready to plot the significant (i.e.Â p-values less than 0.05) hot spot and cold spot areas by using appropriate tmap functions as shown below.

```{r}
HCSA_sig <- HCSA  %>%
  filter(p_sim < 0.05)
tmap_mode("plot")
tm_shape(HCSA) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(HCSA_sig) +
  tm_fill("gi_star") + 
  tm_borders(alpha = 0.4)
```

Figure above reveals that there is one hot spot area and two cold spot areas. Interestingly, the hot spot areas coincide with the High-high cluster identifies by using local Moran\'s I method in the earlier sub-section.
